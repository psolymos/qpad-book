# Organizing and Processing Point Count Data {#pcdata}

> All data are messy, but some are missing

It is often called _data processing_, _data munging_,
_data wrangling_, _data cleaning_.
None of these expressions capture the dread associated with the actual activity.

Luckily, there are only 4 things that can get messed up:

1. space (e.g. wrong UTM zones),
2. time (ISO format please),
3. taxonomy (UNK, mis-ID),
4. something else (if there were no errors, check again).

## JOSM (Joint Oil Sands Monitoring) data

Look at the source code in the `_data/josm` directory of the book
if you are interested in data processing details.
We skip that for now.

```{r data_echo=FALSE}
include_graphics("./_images/mahon-2016-fig-1.png")
```

Cause-Effect Monitoring Migratory Landbirds at Regional Scales: 
understand how boreal songbirds are affected by human activity in the oil sands area.

```{r data_echo=FALSE}
include_graphics("./_images/mahon-2016-fig-2.png")
```

Survey area boundary ($r$=2.5 km circle), habitat type and human footprint mapping, 
and clustered point count site locations.

Surveys were spatially replicated because:

- we want to make inferences about a population,
- full census is out of reach,
- thus we take a sample of the population
- that is representative and random.
- Ideally, sample size should be as large as possible,
- it reduces variability and 
- increases statistical power.

Survey locations were pucked based on various criteria:

- stratification (land cover),
- gradients (disturbance levels),
- random location (control for unmeasured effects),
- take into account historical surveys (avoid, or revisit),
- access, cost (clusters).

The `josm` obejct is a list with 3 elements:

- `surveys`: data frame with survey specific information,
- `species`: lookup table for species,
- `counts`: individual counts by survey and species.

```{r data_load_josm_data}
library(mefa4)
load("./_data/josm/josm.rda")
names(josm)
```

Species info: species codes, common and scientific names. The table could also contain
taxonomic, trait, etc. information as well.

```{r data_josm_species}
head(josm$species)
```

At the survey level, we have coordinates, date/time info,
variables capturing survey conditions, and land cover info extracted from 1 km$^2$ resolution rasters.

```{r data_josm_surveys}
colnames(josm$surveys)
```

The count table contains one row for each unique individual 
of a species (`SpeciesID` links to the species lookup table)
observed during a survey (`StationID` links to the survey attribute table).
Check the data dictionary in `_data/josm` folder for a detailed explanation of each column.

```{r data_josm_counts}
str(josm$counts)
```

## Cross tabulating species counts

Take the following dummy data frame (long format):

```{r data_dummy_data}
(d <- data.frame(
  sample=factor(paste0("S", c(1,1,1,2,2)), paste0("S", 1:3)),
  species=c("BTNW", "OVEN", "CANG", "AMRO", "CANG"),
  abundance=c(1, 1, 2, 1, 1),
  behavior=rep(c("heard","seen"), c(4, 1))))
str(d)
```

We want to add up the `abundance`s for each sample (rows) and species (column):

```{r data_xtab_1}
(y <- Xtab(abundance ~ sample + species, d))
```

`y` is a sparse matrix, that is a very compact representation:

```{r data_xtab_matrix}
object.size(d[,1:3])
object.size(y)
```

Notice that we have 3 rows, but `d$sample` did not have an `S3` value, but it was a level.
We can drop such unused levels, but it is generally not recommended, and we need to be careful
not to drop samples where no species was detected (this can happen quite often depending on timing of
surveys)

```{r data_xtab_2}
Xtab(abundance ~ sample + species, d, drop.unused.levels = TRUE)
```

A sparse matrix can be converted to ordinary matrix

```{r data_xtab_as_matrix}
as.matrix(y)
```


The nice thing about this cross tabulation is that we can finter the records without
changing the structure (rows, columns) of the table:

```{r data_xtab_3}
Xtab(abundance ~ sample + species, d[d$behavior == "heard",])
Xtab(abundance ~ sample + species, d[d$behavior == "seen",])
```

Now let's do this for the real data. We have no abundance column, because 
each row stands for exactly one individual. We can add a column with 1's,
or we can just count the number of rows by using only the right-hand-side of the
formula in `Xtab`. `ytot` will be our total count matrix for now.

We also want to filter the records to contain only `S`ongs and `C`alls, without
`V`visual detections:

```{r data_beh}
table(josm$counts$DetectType1, useNA="always")
```

We use `SiteID` for row names, because only 1 station and visit was done at each site:

```{r data_xtab_4}
ytot <- Xtab(~ SiteID + SpeciesID , josm$counts[josm$counts$DetectType1 != "V",])
```

See how not storing 0's affect size compared to the long formar and an ordinary wide matrix

```{r data_xtab_matrix_2}
## 2-column data frame as reference
tmp <- as.numeric(object.size(
  josm$counts[josm$counts$DetectType1 != "V", c("StationID", "SpeciesID")]))
## spare matrix
as.numeric(object.size(ytot)) / tmp
## dense matrix
as.numeric(object.size(as.matrix(ytot))) / tmp
## matrix fill
sum(ytot > 0) / prod(dim(ytot))
```

Check if counts are as expected:

```{r}
max(ytot) # this is interesting
sort(apply(as.matrix(ytot), 2, max)) # it is CANG
## lyover (FO) flock (FL) beyond 100m distance
head(josm$counts[
  josm$counts$SiteID == rownames(ytot)[which(ytot[,"CANG"] == 200)] &
  josm$counts$SpeciesID == "CANG",])
```

We can check overall mean counts

```{r data_mean_counts}
round(sort(colMeans(ytot)), 4)
```

## Joining species data with predictors

Let's join the species counts with the survey attributes. This is how we can prepare the
input data for regression analysis.

```{r data_join}
spp <- "OVEN" # which species
josm$species[spp,]

compare_sets(rownames(x),rownames(ytot))

x <- josm$surveys
x$y <- as.numeric(ytot[rownames(x), spp])
```

## Explore predictor variables

Locations

```{r data_xy}
library(raster)
library(sp)
rr <- stack("./_data/josm/landcover-hfi2016.grd")
#' Define CRS NAD83 for our sites
xy <- x[,c("Longitude", "Latitude")]
coordinates(xy) <- ~ Longitude + Latitude
proj4string(xy) <- "+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"
xy <- spTransform(xy, proj4string(rr))
col <- colorRampPalette(c("lightgrey", "blue"))(100)
plot(rr[["Water"]], col=col, axes=FALSE, box=FALSE)
plot(xy, add=TRUE, pch=19, cex=0.5)
```

```{r data_pred}
cn <- c("Open", "Water", "Agr", "UrbInd", "SoftLin", "Roads", 
  "Decid", "OpenWet", "Conif", "ConifWet")
plot(x[,cn])
```


Add here:

- those kinds of transformations that are needed for regression

Exercise: 

- play with the data to understand the distributions
- use `summary`, `table`, `hist`, `plot`
