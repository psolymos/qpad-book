<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 The Detection Process | Point count data analysis: How to violate assumptions and get away with it</title>
  <meta name="description" content="This book provides material for the workshop ‘Analysis of point-count data in the presence of variable survey methodologies and detection error’ at the AOS 2019 conference." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 The Detection Process | Point count data analysis: How to violate assumptions and get away with it" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://peter.solymos.org/qpad-book/" />
  <meta property="og:image" content="http://peter.solymos.org/qpad-book/images/cover.png" />
  <meta property="og:description" content="This book provides material for the workshop ‘Analysis of point-count data in the presence of variable survey methodologies and detection error’ at the AOS 2019 conference." />
  <meta name="github-repo" content="psolymos/qpad-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 The Detection Process | Point count data analysis: How to violate assumptions and get away with it" />
  
  <meta name="twitter:description" content="This book provides material for the workshop ‘Analysis of point-count data in the presence of variable survey methodologies and detection error’ at the AOS 2019 conference." />
  <meta name="twitter:image" content="http://peter.solymos.org/qpad-book/images/cover.png" />

<meta name="author" content="Peter Solymos" />


<meta name="date" content="2019-06-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="behavior.html">
<link rel="next" href="recordings.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">QPAD Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-book-and-the-course"><i class="fa fa-check"></i>About the book and the course</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installing-r-and-rstudio"><i class="fa fa-check"></i>Installing R and RStudio</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installing-required-packages"><i class="fa fa-check"></i>Installing required packages</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installing-the-book"><i class="fa fa-check"></i>Installing the book</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-this-works"><i class="fa fa-check"></i>How this works</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#design-based-approaches"><i class="fa fa-check"></i><b>1.1</b> Design-based approaches</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#model-based-approaches"><i class="fa fa-check"></i><b>1.2</b> Model-based approaches</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#our-approach"><i class="fa fa-check"></i><b>1.3</b> Our approach</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pcdata.html"><a href="pcdata.html"><i class="fa fa-check"></i><b>2</b> Organizing and Processing Point Count Data</a><ul>
<li class="chapter" data-level="2.1" data-path="pcdata.html"><a href="pcdata.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="pcdata.html"><a href="pcdata.html#prerequisites"><i class="fa fa-check"></i><b>2.2</b> Prerequisites</a></li>
<li class="chapter" data-level="2.3" data-path="pcdata.html"><a href="pcdata.html#rbasics"><i class="fa fa-check"></i><b>2.3</b> R basics</a></li>
<li class="chapter" data-level="2.4" data-path="pcdata.html"><a href="pcdata.html#josm-data-set"><i class="fa fa-check"></i><b>2.4</b> JOSM data set</a></li>
<li class="chapter" data-level="2.5" data-path="pcdata.html"><a href="pcdata.html#cross-tabulating-species-counts"><i class="fa fa-check"></i><b>2.5</b> Cross tabulating species counts</a></li>
<li class="chapter" data-level="2.6" data-path="pcdata.html"><a href="pcdata.html#joining-species-data-with-predictors"><i class="fa fa-check"></i><b>2.6</b> Joining species data with predictors</a></li>
<li class="chapter" data-level="2.7" data-path="pcdata.html"><a href="pcdata.html#explore-predictor-variables"><i class="fa fa-check"></i><b>2.7</b> Explore predictor variables</a></li>
<li class="chapter" data-level="2.8" data-path="pcdata.html"><a href="pcdata.html#derived-variables"><i class="fa fa-check"></i><b>2.8</b> Derived variables</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>3</b> A Primer in Regression Techniques</a><ul>
<li class="chapter" data-level="3.1" data-path="regression.html"><a href="regression.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="regression.html"><a href="regression.html#prerequisites-1"><i class="fa fa-check"></i><b>3.2</b> Prerequisites</a></li>
<li class="chapter" data-level="3.3" data-path="regression.html"><a href="regression.html#poisson-null-model"><i class="fa fa-check"></i><b>3.3</b> Poisson null model</a></li>
<li class="chapter" data-level="3.4" data-path="regression.html"><a href="regression.html#exploring-covariates"><i class="fa fa-check"></i><b>3.4</b> Exploring covariates</a></li>
<li class="chapter" data-level="3.5" data-path="regression.html"><a href="regression.html#single-covariate"><i class="fa fa-check"></i><b>3.5</b> Single covariate</a></li>
<li class="chapter" data-level="3.6" data-path="regression.html"><a href="regression.html#additive-model"><i class="fa fa-check"></i><b>3.6</b> Additive model</a></li>
<li class="chapter" data-level="3.7" data-path="regression.html"><a href="regression.html#nonlinear-terms"><i class="fa fa-check"></i><b>3.7</b> Nonlinear terms</a></li>
<li class="chapter" data-level="3.8" data-path="regression.html"><a href="regression.html#categorical-variables"><i class="fa fa-check"></i><b>3.8</b> Categorical variables</a></li>
<li class="chapter" data-level="3.9" data-path="regression.html"><a href="regression.html#multiple-main-effects"><i class="fa fa-check"></i><b>3.9</b> Multiple main effects</a></li>
<li class="chapter" data-level="3.10" data-path="regression.html"><a href="regression.html#interaction"><i class="fa fa-check"></i><b>3.10</b> Interaction</a></li>
<li class="chapter" data-level="3.11" data-path="regression.html"><a href="regression.html#different-error-distributions"><i class="fa fa-check"></i><b>3.11</b> Different error distributions</a></li>
<li class="chapter" data-level="3.12" data-path="regression.html"><a href="regression.html#count-duration-effects"><i class="fa fa-check"></i><b>3.12</b> Count duration effects</a></li>
<li class="chapter" data-level="3.13" data-path="regression.html"><a href="regression.html#count-radius-effects"><i class="fa fa-check"></i><b>3.13</b> Count radius effects</a></li>
<li class="chapter" data-level="3.14" data-path="regression.html"><a href="regression.html#offsets"><i class="fa fa-check"></i><b>3.14</b> Offsets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="behavior.html"><a href="behavior.html"><i class="fa fa-check"></i><b>4</b> Behavioral Complexities</a><ul>
<li class="chapter" data-level="4.1" data-path="behavior.html"><a href="behavior.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="behavior.html"><a href="behavior.html#prerequisites-2"><i class="fa fa-check"></i><b>4.2</b> Prerequisites</a></li>
<li class="chapter" data-level="4.3" data-path="behavior.html"><a href="behavior.html#birds-in-the-forest"><i class="fa fa-check"></i><b>4.3</b> Birds in the forest</a></li>
<li class="chapter" data-level="4.4" data-path="behavior.html"><a href="behavior.html#survival-model"><i class="fa fa-check"></i><b>4.4</b> Survival model</a></li>
<li class="chapter" data-level="4.5" data-path="behavior.html"><a href="behavior.html#vocalization-events"><i class="fa fa-check"></i><b>4.5</b> Vocalization events</a></li>
<li class="chapter" data-level="4.6" data-path="behavior.html"><a href="behavior.html#removal-model"><i class="fa fa-check"></i><b>4.6</b> Removal model</a><ul>
<li class="chapter" data-level="4.6.1" data-path="behavior.html"><a href="behavior.html#real-data"><i class="fa fa-check"></i><b>4.6.1</b> Real data</a></li>
<li class="chapter" data-level="4.6.2" data-path="behavior.html"><a href="behavior.html#time-invariant-conventional-model"><i class="fa fa-check"></i><b>4.6.2</b> Time-invariant conventional model</a></li>
<li class="chapter" data-level="4.6.3" data-path="behavior.html"><a href="behavior.html#time-varying-conventional-removal-model"><i class="fa fa-check"></i><b>4.6.3</b> Time-varying conventional removal model</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="behavior.html"><a href="behavior.html#finite-mixtures"><i class="fa fa-check"></i><b>4.7</b> Finite mixtures</a><ul>
<li class="chapter" data-level="4.7.1" data-path="behavior.html"><a href="behavior.html#time-invariant-finite-mixture-removal-model"><i class="fa fa-check"></i><b>4.7.1</b> Time-invariant finite mixture removal model</a></li>
<li class="chapter" data-level="4.7.2" data-path="behavior.html"><a href="behavior.html#time-varying-finite-mixture-removal-models"><i class="fa fa-check"></i><b>4.7.2</b> Time-varying finite mixture removal models</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="behavior.html"><a href="behavior.html#let-the-best-model-win"><i class="fa fa-check"></i><b>4.8</b> Let the best model win</a></li>
<li class="chapter" data-level="4.9" data-path="behavior.html"><a href="behavior.html#estimating-abundance"><i class="fa fa-check"></i><b>4.9</b> Estimating abundance</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="detection.html"><a href="detection.html"><i class="fa fa-check"></i><b>5</b> The Detection Process</a><ul>
<li class="chapter" data-level="5.1" data-path="detection.html"><a href="detection.html#introduction-3"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="detection.html"><a href="detection.html#prerequisites-3"><i class="fa fa-check"></i><b>5.2</b> Prerequisites</a></li>
<li class="chapter" data-level="5.3" data-path="detection.html"><a href="detection.html#distance-functions"><i class="fa fa-check"></i><b>5.3</b> Distance functions</a></li>
<li class="chapter" data-level="5.4" data-path="detection.html"><a href="detection.html#distance-sampling"><i class="fa fa-check"></i><b>5.4</b> Distance sampling</a></li>
<li class="chapter" data-level="5.5" data-path="detection.html"><a href="detection.html#average-detection"><i class="fa fa-check"></i><b>5.5</b> Average detection</a></li>
<li class="chapter" data-level="5.6" data-path="detection.html"><a href="detection.html#binned-distances"><i class="fa fa-check"></i><b>5.6</b> Binned distances</a></li>
<li class="chapter" data-level="5.7" data-path="detection.html"><a href="detection.html#availability-bias"><i class="fa fa-check"></i><b>5.7</b> Availability bias</a></li>
<li class="chapter" data-level="5.8" data-path="detection.html"><a href="detection.html#estimating-density-with-truncation"><i class="fa fa-check"></i><b>5.8</b> Estimating density with truncation</a></li>
<li class="chapter" data-level="5.9" data-path="detection.html"><a href="detection.html#unlimited-distance"><i class="fa fa-check"></i><b>5.9</b> Unlimited distance</a></li>
<li class="chapter" data-level="5.10" data-path="detection.html"><a href="detection.html#replicating-landscapes"><i class="fa fa-check"></i><b>5.10</b> Replicating landscapes</a></li>
<li class="chapter" data-level="5.11" data-path="detection.html"><a href="detection.html#josm-data"><i class="fa fa-check"></i><b>5.11</b> JOSM data</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="recordings.html"><a href="recordings.html"><i class="fa fa-check"></i><b>6</b> Dealing with Recordings</a><ul>
<li class="chapter" data-level="6.1" data-path="recordings.html"><a href="recordings.html#introduction-4"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="recordings.html"><a href="recordings.html#prerequisites-4"><i class="fa fa-check"></i><b>6.2</b> Prerequisites</a></li>
<li class="chapter" data-level="6.3" data-path="recordings.html"><a href="recordings.html#paired-sampling"><i class="fa fa-check"></i><b>6.3</b> Paired sampling</a></li>
<li class="chapter" data-level="6.4" data-path="recordings.html"><a href="recordings.html#paired-data"><i class="fa fa-check"></i><b>6.4</b> Paired data</a></li>
<li class="chapter" data-level="6.5" data-path="recordings.html"><a href="recordings.html#availability"><i class="fa fa-check"></i><b>6.5</b> Availability</a></li>
<li class="chapter" data-level="6.6" data-path="recordings.html"><a href="recordings.html#distance-sampling-1"><i class="fa fa-check"></i><b>6.6</b> Distance sampling</a></li>
<li class="chapter" data-level="6.7" data-path="recordings.html"><a href="recordings.html#scaling-constant"><i class="fa fa-check"></i><b>6.7</b> Scaling constant</a></li>
<li class="chapter" data-level="6.8" data-path="recordings.html"><a href="recordings.html#data-integration"><i class="fa fa-check"></i><b>6.8</b> Data integration</a></li>
<li class="chapter" data-level="6.9" data-path="recordings.html"><a href="recordings.html#abmi-data"><i class="fa fa-check"></i><b>6.9</b> ABMI data</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>7</b> A Closer Look at Assumptions</a><ul>
<li class="chapter" data-level="7.1" data-path="assumptions.html"><a href="assumptions.html#intro-1"><i class="fa fa-check"></i><b>7.1</b> Intro</a></li>
<li class="chapter" data-level="7.2" data-path="assumptions.html"><a href="assumptions.html#prerequisites-5"><i class="fa fa-check"></i><b>7.2</b> Prerequisites</a></li>
<li class="chapter" data-level="7.3" data-path="assumptions.html"><a href="assumptions.html#bsims-runs"><i class="fa fa-check"></i><b>7.3</b> bSims runs</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="roadsides.html"><a href="roadsides.html"><i class="fa fa-check"></i><b>8</b> Understanding Roadside Surveys</a></li>
<li class="chapter" data-level="9" data-path="extras.html"><a href="extras.html"><i class="fa fa-check"></i><b>9</b> Miscellaneous Topics</a><ul>
<li class="chapter" data-level="" data-path="extras.html"><a href="extras.html#these-are-just-reminders-to-be-deleted-later"><i class="fa fa-check"></i>These are just reminders, to be deleted later</a></li>
<li class="chapter" data-level="9.1" data-path="extras.html"><a href="extras.html#binomial-model-and-censoring"><i class="fa fa-check"></i><b>9.1</b> Binomial model and censoring</a></li>
<li class="chapter" data-level="9.2" data-path="extras.html"><a href="extras.html#optimal-partitioning"><i class="fa fa-check"></i><b>9.2</b> Optimal partitioning</a></li>
<li class="chapter" data-level="9.3" data-path="extras.html"><a href="extras.html#optilevels"><i class="fa fa-check"></i><b>9.3</b> Optilevels</a></li>
<li class="chapter" data-level="9.4" data-path="extras.html"><a href="extras.html#n-mixture-models"><i class="fa fa-check"></i><b>9.4</b> N-mixture models</a></li>
<li class="chapter" data-level="9.5" data-path="extras.html"><a href="extras.html#estimating-abundance-1"><i class="fa fa-check"></i><b>9.5</b> Estimating abundance</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="http://peter.solymos.org/" target="blank">P&eacute;ter S&oacute;lymos</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Point count data analysis: How to violate assumptions and get away with it</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="detection" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> The Detection Process</h1>
<div id="introduction-3" class="section level2">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<p>As part of the detection process, a skilled observer
counts individual birds at a count station.
New individuals are assigned to time and distance categories,
the type of behavior also registered.
During this process, auditory cues travel through
the distance between the bird and the observer.
As the pover of the sound fades away, the
chanches of being detected also decreases.
If the detection process is based on visual detections,
vegetation can block line of sight, etc.
In this chapter, we scrutinize how this detection process
contributes to the factor <span class="math inline">\(C\)</span>.</p>
</div>
<div id="prerequisites-3" class="section level2">
<h2><span class="header-section-number">5.2</span> Prerequisites</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bSims)                <span class="co"># simulations</span>
<span class="kw">library</span>(detect)               <span class="co"># multinomial models</span>
<span class="kw">library</span>(Distance)             <span class="co"># distance sampling</span>
<span class="kw">load</span>(<span class="st">&quot;_data/josm/josm.rda&quot;</span>)   <span class="co"># JOSM data</span>
<span class="kw">source</span>(<span class="st">&quot;functions.R&quot;</span>)         <span class="co"># some useful stuff</span></code></pre>
</div>
<div id="distance-functions" class="section level2">
<h2><span class="header-section-number">5.3</span> Distance functions</h2>
<p>The distance function (<span class="math inline">\(g(d)\)</span> describes the probability of detecting an individual
given the distance between the observer and the individual (<span class="math inline">\(d\)</span>).
The detection itself is often triggered by visual or auditory cues,
and thus depend on the individuals being available for detection
(and of course being present in the survey area).</p>
<p>Distance functions have some characteristics:</p>
<ul>
<li>It is a monotonic decreasing function of distance,</li>
<li><span class="math inline">\(g(0)=1\)</span>: detection at 0 distance is perfect.</li>
</ul>
<p>Here are some common distance function and rationale for their use
(i.e. mechanisms leading to such distance shapes):</p>
<ol style="list-style-type: decimal">
<li>Negative Exponential: a one-parameter function (<span class="math inline">\(g(d) = e^{-d/\tau}\)</span>), probability quickly decreases with distance, this mirrors sound attenuation under spherical spreading, so might be a suitable form for acoustic recoding devices (we will revisit this later), but not a very useful form for human based counts, as explained below;</li>
<li>Half-Normal: this is also a one-parameter function (<span class="math inline">\(g(d) = e^{-(d/\tau)^2}\)</span>) where probability initially remain high (the <em>shoulder</em>), reflecting an increased chance of detecting individuals closer to the observer, this form has also sone practical advantages that we will discuss shortly (<span class="math inline">\(\tau^2\)</span> is variance of the unfolded Normal distribution, <span class="math inline">\(\tau^2/2\)</span> is the variance of the Half-Normal distribution – both the Negative Exponential and the Half-Normal being special cases of <span class="math inline">\(g(d) = e^{-(d/\tau)^b}\)</span> that have the parameter <span class="math inline">\(b\)</span> [<span class="math inline">\(b &gt; 0\)</span>] affecting the shoulder);</li>
<li>Hazard rate: this is a two-parameter model (<span class="math inline">\(g(d) = 1-e^{-(d/\tau)^-b}\)</span>) that have the parameter <span class="math inline">\(b\)</span> (<span class="math inline">\(b &gt; 0\)</span>) affecting the more pronounced and sharp shoulder.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">d &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="fl">0.01</span>)
<span class="kw">plot</span>(d, <span class="kw">exp</span>(<span class="op">-</span>d<span class="op">/</span><span class="fl">0.8</span>), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="dv">4</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),
  <span class="dt">xlab=</span><span class="st">&quot;Distance (100 m)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;P(detection)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Negative Exponential&quot;</span>)
<span class="kw">plot</span>(d, <span class="kw">exp</span>(<span class="op">-</span>(d<span class="op">/</span><span class="fl">0.8</span>)<span class="op">^</span><span class="dv">2</span>), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="dv">4</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),
  <span class="dt">xlab=</span><span class="st">&quot;Distance (100 m)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;P(detection)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Half-Normal&quot;</span>)
<span class="kw">plot</span>(d, <span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(d<span class="op">/</span><span class="fl">0.8</span>)<span class="op">^-</span><span class="dv">4</span>), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="dv">4</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),
  <span class="dt">xlab=</span><span class="st">&quot;Distance (100 m)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;P(detection)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Hazard rate&quot;</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-78-1.png" width="33%" /><img src="qpad-book_files/figure-html/unnamed-chunk-78-2.png" width="33%" /><img src="qpad-book_files/figure-html/unnamed-chunk-78-3.png" width="33%" /></p>

<div class="rmdexercise">
<p><strong>Exercise</strong></p>
<p>Try different values of <span class="math inline">\(b\)</span> to explore the different shapes of the Hazard rate function.</p>
Write your own code (<code>plot(d, exp(-(d/&lt;tau&gt;)^&lt;b&gt;), type=&quot;l&quot;, ylim=c(0,1))</code>), or run <code>shiny::runApp(&quot;_shiny/distancefun.R&quot;)</code>.
</div>

<p>We will apply this new found knowledge to our bSims world:
the observer is in the middle of the landscape, and each vocalization
event is aither detected or not, depending on the distance.
Units of <code>tau</code> are given on 100 m units, so that corresponding
density estimates will refer to ha as the unit area.</p>
<p>In this example, we want all individuals to be equally available,
so we are going to override all behavioral aspects of the simulations
by the <code>initial_location</code> argument when calling <code>bsims_animate</code>.
We set <code>density</code> and <code>tau</code> high enough to detections in this example.</p>
<pre class="sourceCode r"><code class="sourceCode r">tau &lt;-<span class="st"> </span><span class="dv">2</span>

<span class="kw">set.seed</span>(<span class="dv">123</span>)
l &lt;-<span class="st"> </span><span class="kw">bsims_init</span>()
a &lt;-<span class="st"> </span><span class="kw">bsims_populate</span>(l, <span class="dt">density=</span><span class="dv">10</span>)
b &lt;-<span class="st"> </span><span class="kw">bsims_animate</span>(a, <span class="dt">initial_location=</span><span class="ot">TRUE</span>)

(o &lt;-<span class="st"> </span><span class="kw">bsims_detect</span>(b, <span class="dt">tau=</span>tau))</code></pre>
<pre><code>## bSims detections
##   1 km x 1 km
##   stratification: H
##   total abundance: 1013
##   no events, duration: 10 min
##   detected: 128 seen/heard</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(o)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-81-1.png" width="768" /></p>
</div>
<div id="distance-sampling" class="section level2">
<h2><span class="header-section-number">5.4</span> Distance sampling</h2>
<p>The distribution of the <em>observed distances</em> is a product of detectability
and the distribution of the individuals with respect to the point where
the observer is located.
For point counts, area increases linearly with radial distance,
implying a triangular distribution with respect to the point
(<span class="math inline">\(h(d)=\pi 2 d /A=\pi 2 d / \pi r_{max}^2=2 d / r_{max}^2\)</span>, where
<span class="math inline">\(A\)</span> is a circular survey area with truncation distance <span class="math inline">\(r_{max}\)</span>).
The product <span class="math inline">\(g(d) h(d)\)</span> gives the density function of the observed distances.</p>
<pre class="sourceCode r"><code class="sourceCode r">g &lt;-<span class="st"> </span><span class="cf">function</span>(d, tau, <span class="dt">b=</span><span class="dv">2</span>, <span class="dt">hazard=</span><span class="ot">FALSE</span>)
  <span class="cf">if</span> (hazard)
    <span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(d<span class="op">/</span>tau)<span class="op">^-</span>b) <span class="cf">else</span> <span class="kw">exp</span>(<span class="op">-</span>(d<span class="op">/</span>tau)<span class="op">^</span>b)
h &lt;-<span class="st"> </span><span class="cf">function</span>(d, rmax)
  <span class="dv">2</span><span class="op">*</span>d<span class="op">/</span>rmax<span class="op">^</span><span class="dv">2</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">rmax &lt;-<span class="st"> </span><span class="dv">4</span>

d &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, rmax, <span class="fl">0.01</span>)
<span class="kw">plot</span>(d, <span class="kw">g</span>(d, tau), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="dv">4</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),
  <span class="dt">xlab=</span><span class="st">&quot;d&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;g(d)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Prob. of detection&quot;</span>)
<span class="kw">plot</span>(d, <span class="kw">h</span>(d, rmax), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="dv">4</span>,
  <span class="dt">xlab=</span><span class="st">&quot;d&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;h(d)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;PDF of distances&quot;</span>)
<span class="kw">plot</span>(d, <span class="kw">g</span>(d, tau) <span class="op">*</span><span class="st"> </span><span class="kw">h</span>(d, rmax), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="dv">4</span>,
  <span class="dt">xlab=</span><span class="st">&quot;d&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;g(d) h(d)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;Density of observed distances&quot;</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-83-1.png" width="33%" /><img src="qpad-book_files/figure-html/unnamed-chunk-83-2.png" width="33%" /><img src="qpad-book_files/figure-html/unnamed-chunk-83-3.png" width="33%" /></p>
<p>The object <code>da</code> contains the distances to all the nests
based on our bSims object,
we use this to display the distribution of available distances:</p>
<pre class="sourceCode r"><code class="sourceCode r">da &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">rowSums</span>(a<span class="op">$</span>nests[,<span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>)]<span class="op">^</span><span class="dv">2</span>))

<span class="kw">hist</span>(da[da <span class="op">&lt;=</span><span class="st"> </span>rmax], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, rmax),
  <span class="dt">xlab=</span><span class="st">&quot;Available distances (d &lt;= r_max)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="dv">2</span><span class="op">*</span>x<span class="op">/</span>rmax<span class="op">^</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="dv">2</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
<p>The <code>get_detections</code> function returns a data frame with the
detected events (in our case just the nest locations):
<code>$d</code> is the distance, <code>$a</code> is the angle
(in degrees, counter clock-wise from positive x axis).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(dt &lt;-<span class="st"> </span><span class="kw">get_detections</span>(o))</code></pre>
<p>The following code plots the probability density of the
observed distances within the truncation distance <span class="math inline">\(r_{max}\)</span>,
thus we need to standardize the <span class="math inline">\(g(r) h(r)\)</span> function
by the integral sum:</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(d, tau, <span class="dt">b=</span><span class="dv">2</span>, <span class="dt">hazard=</span><span class="ot">FALSE</span>, <span class="dt">rmax=</span><span class="dv">1</span>) 
  <span class="kw">g</span>(d, tau, b, hazard) <span class="op">*</span><span class="st"> </span><span class="kw">h</span>(d, rmax)
tot &lt;-<span class="st"> </span><span class="kw">integrate</span>(f, <span class="dt">lower=</span><span class="dv">0</span>, <span class="dt">upper=</span>rmax, <span class="dt">tau=</span>tau, <span class="dt">rmax=</span>rmax)<span class="op">$</span>value

<span class="kw">hist</span>(dt<span class="op">$</span>d[dt<span class="op">$</span>d <span class="op">&lt;=</span><span class="st"> </span>rmax], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, rmax),
  <span class="dt">xlab=</span><span class="st">&quot;Observed distances (r &lt;= rmax)&quot;</span>, <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="dt">tau=</span>tau, <span class="dt">rmax=</span>rmax) <span class="op">/</span><span class="st"> </span>tot, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="dv">2</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-86-1.png" width="672" /></p>
<p>In case of the Half-Normal, we can linearize the relationship
by taking the log of the distance function:
<span class="math inline">\(log(g(d)) =log(e^{-(d/\tau)^2})= -(d / \tau)^2 = x \frac{1}{\tau^2} = 0 + x \beta\)</span>.
Consequently, we can use GLM to fit a model with <span class="math inline">\(x = -d^2\)</span> as
predictor and no intercept, and estimate <span class="math inline">\(\hat{\beta}\)</span> and
<span class="math inline">\(\hat{\tau}=\sqrt{1/\hat{\beta}}\)</span>.</p>
<p>For this method to work, we need to know the observed and
unobserved distances as well,
which makes this approach of low utility in practice when
location of unobserved individuals is unknown.
But we can at least check our bSims data:</p>
<pre class="sourceCode r"><code class="sourceCode r">dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">distance=</span>da, 
  <span class="dt">x=</span><span class="op">-</span>da<span class="op">^</span><span class="dv">2</span>, 
  <span class="dt">detected=</span><span class="kw">ifelse</span>(<span class="kw">rownames</span>(o<span class="op">$</span>nests) <span class="op">%in%</span><span class="st"> </span>dt<span class="op">$</span>i, <span class="dv">1</span>, <span class="dv">0</span>))
<span class="kw">summary</span>(dat)</code></pre>
<pre><code>##     distance           x             detected    
##  Min.   :0.226   Min.   :-49.33   Min.   :0.000  
##  1st Qu.:2.876   1st Qu.:-23.74   1st Qu.:0.000  
##  Median :3.965   Median :-15.72   Median :0.000  
##  Mean   :3.827   Mean   :-16.69   Mean   :0.126  
##  3rd Qu.:4.872   3rd Qu.: -8.27   3rd Qu.:0.000  
##  Max.   :7.024   Max.   : -0.05   Max.   :1.000</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">mod &lt;-<span class="st"> </span><span class="kw">glm</span>(detected <span class="op">~</span><span class="st"> </span>x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>dat, <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">&quot;log&quot;</span>))
<span class="kw">c</span>(<span class="dt">true=</span>tau, <span class="dt">estimate=</span><span class="kw">sqrt</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">coef</span>(mod)))</code></pre>
<pre><code>##       true estimate.x 
##      2.000      2.034</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">exp</span>(<span class="op">-</span>(x<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">coef</span>(mod)))<span class="op">^</span><span class="dv">2</span>), 
  <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="kw">max</span>(dat<span class="op">$</span>distance)), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),
  <span class="dt">xlab=</span><span class="st">&quot;Distance (100 m)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;P(detection)&quot;</span>)
<span class="kw">curve</span>(<span class="kw">exp</span>(<span class="op">-</span>(x<span class="op">/</span>tau)<span class="op">^</span><span class="dv">2</span>), <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">rug</span>(dat<span class="op">$</span>distance[dat<span class="op">$</span>detected <span class="op">==</span><span class="st"> </span><span class="dv">0</span>], <span class="dt">side=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="dv">4</span>)
<span class="kw">rug</span>(dat<span class="op">$</span>distance[dat<span class="op">$</span>detected <span class="op">==</span><span class="st"> </span><span class="dv">1</span>], <span class="dt">side=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), 
  <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;True&quot;</span>, <span class="st">&quot;Estimated&quot;</span>))</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-88-1.png" width="672" /></p>
<p>The Distance package offers various tools to fit
models to observed distance data.
See <a href="https://workshops.distancesampling.org/duke-spatial-2015/practicals/1-detection-functions-solutions.html">here</a> for a tutorial.
The following script fits the Half-Normal (<code>key = &quot;hn&quot;</code>)
without ajustments (<code>adjustment=NULL</code>) to<br />
observed distance data from truncated point transect.
It estimates <span class="math inline">\(\sigma = \sqrt{\tau}\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">dd &lt;-<span class="st"> </span><span class="kw">ds</span>(dt<span class="op">$</span>d, <span class="dt">truncation =</span> rmax, <span class="dt">transect=</span><span class="st">&quot;point&quot;</span>, 
  <span class="dt">key =</span> <span class="st">&quot;hn&quot;</span>, <span class="dt">adjustment=</span><span class="ot">NULL</span>)</code></pre>
<pre><code>## Fitting half-normal key function</code></pre>
<pre><code>## Key only model: not constraining for monotonicity.</code></pre>
<pre><code>## AIC= 315.502</code></pre>
<pre><code>## No survey area information supplied, only estimating detection function.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">c</span>(<span class="dt">true=</span>tau, <span class="dt">estimate=</span><span class="kw">exp</span>(dd<span class="op">$</span>ddf<span class="op">$</span>par)<span class="op">^</span><span class="dv">2</span>)</code></pre>
<pre><code>##     true estimate 
##    2.000    2.176</code></pre>
</div>
<div id="average-detection" class="section level2">
<h2><span class="header-section-number">5.5</span> Average detection</h2>
<p>To calculate the average probability of detecting individuals
within a circle with truncation distance <span class="math inline">\(r_{max}\)</span>, we need to
integrate over the product of <span class="math inline">\(g(r)\)</span> and <span class="math inline">\(h(r)\)</span>:
<span class="math inline">\(q(r_{max})=\int_{0}^{r_{max}} g(d) h(d) dd\)</span>.
This gives the volume of pie dough cut at <span class="math inline">\(r_{max}\)</span>,
compared to the volume of the cookie cutter (<span class="math inline">\(\pi r_{max}^2\)</span>).</p>
<pre class="sourceCode r"><code class="sourceCode r">q &lt;-<span class="st"> </span><span class="kw">sapply</span>(d[d <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>], <span class="cf">function</span>(z)
  <span class="kw">integrate</span>(f, <span class="dt">lower=</span><span class="dv">0</span>, <span class="dt">upper=</span>z, <span class="dt">tau=</span>tau, <span class="dt">rmax=</span>z)<span class="op">$</span>value)

<span class="kw">plot</span>(d, <span class="kw">c</span>(<span class="dv">1</span>, q), <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">col=</span><span class="dv">4</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),
  <span class="dt">xlab=</span><span class="kw">expression</span>(r[max]), <span class="dt">ylab=</span><span class="kw">expression</span>(<span class="kw">q</span>(r[max])), 
  <span class="dt">main=</span><span class="st">&quot;Average prob. of detection&quot;</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-90-1.png" width="672" /></p>
<p>For the Half-Normal detection function, the analytical solution for the
average probability is
<span class="math inline">\(\pi \tau^2 [1-exp(-d^2/\tau^2)] / (\pi r_{max}^2)\)</span>,
where the denominator is a normalizing constant
representing the volume of a cylinder of perfect detectability.</p>
<p>To visualize this, here is the pie analogy for
<span class="math inline">\(\tau=2\)</span> and <span class="math inline">\(r_{max}=2\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">tau &lt;-<span class="st"> </span><span class="dv">2</span>
rmax &lt;-<span class="st"> </span><span class="dv">2</span>
w &lt;-<span class="st"> </span><span class="fl">0.1</span>
m &lt;-<span class="st"> </span><span class="dv">2</span>
<span class="kw">plot</span>(<span class="dv">0</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>, <span class="dt">xlim=</span>m<span class="op">*</span><span class="kw">c</span>(<span class="op">-</span>rmax, rmax), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span>w, <span class="dv">1</span><span class="op">+</span>w), 
  <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">ann=</span><span class="ot">FALSE</span>)
yh &lt;-<span class="st"> </span><span class="kw">g</span>(rmax, <span class="dt">tau=</span>tau)
<span class="kw">lines</span>(<span class="kw">seq</span>(<span class="op">-</span>rmax, rmax, rmax<span class="op">/</span><span class="dv">100</span>),
  <span class="kw">g</span>(<span class="kw">abs</span>(<span class="kw">seq</span>(<span class="op">-</span>rmax, rmax, rmax<span class="op">/</span><span class="dv">100</span>)), <span class="dt">tau=</span>tau))
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, yh, rmax, w, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="op">-</span><span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(<span class="dv">0</span>, yh))
<span class="kw">lines</span>(<span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(<span class="dv">0</span>, yh))
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, <span class="dv">0</span>, rmax, w)
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, <span class="dv">1</span>, rmax, w, <span class="dt">border=</span><span class="dv">4</span>)
<span class="kw">lines</span>(<span class="op">-</span><span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(yh, <span class="dv">1</span>), <span class="dt">col=</span><span class="dv">4</span>)
<span class="kw">lines</span>(<span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(yh, <span class="dv">1</span>), <span class="dt">col=</span><span class="dv">4</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-91-1.png" width="672" /></p>
</div>
<div id="binned-distances" class="section level2">
<h2><span class="header-section-number">5.6</span> Binned distances</h2>
<p>The cumulative density function for the Half-Normal
distribution (<span class="math inline">\(\pi(r) = 1-e^{-(r/\tau)^2}\)</span>) is used to calculate
cell probabilities for binned distance data
(the normalizing constant is the area of the integral <span class="math inline">\(\pi \tau^2\)</span>,
instead of <span class="math inline">\(\pi r_{max}^2\)</span>).
It captures the proportion of the observed distances
relative to the whole volume of the observed distance density.
In the pie analogy, this is the dough volume inside
the cookie cutter, compared to the dough volume inside and outside
of the cutter (that happens to be <span class="math inline">\(\pi \tau^2\)</span> for the Half-Normal):</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="dv">0</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>, <span class="dt">xlim=</span>m<span class="op">*</span><span class="kw">c</span>(<span class="op">-</span>rmax, rmax), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span>w, <span class="dv">1</span><span class="op">+</span>w), 
  <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">ann=</span><span class="ot">FALSE</span>)
yh &lt;-<span class="st"> </span><span class="kw">g</span>(rmax, <span class="dt">tau=</span>tau)
<span class="kw">lines</span>(<span class="kw">seq</span>(<span class="op">-</span>m<span class="op">*</span>rmax, m<span class="op">*</span>rmax, rmax<span class="op">/</span>(m<span class="op">*</span><span class="dv">100</span>)),
  <span class="kw">g</span>(<span class="kw">seq</span>(<span class="op">-</span>m<span class="op">*</span>rmax, m<span class="op">*</span>rmax, rmax<span class="op">/</span>(m<span class="op">*</span><span class="dv">100</span>)), <span class="dt">tau=</span>tau),
  <span class="dt">col=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="kw">seq</span>(<span class="op">-</span>rmax, rmax, rmax<span class="op">/</span><span class="dv">100</span>),
  <span class="kw">g</span>(<span class="kw">abs</span>(<span class="kw">seq</span>(<span class="op">-</span>rmax, rmax, rmax<span class="op">/</span><span class="dv">100</span>)), <span class="dt">tau=</span>tau))
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, yh, rmax, w, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="op">-</span><span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(<span class="dv">0</span>, yh))
<span class="kw">lines</span>(<span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(<span class="dv">0</span>, yh))
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, <span class="dv">0</span>, rmax, w)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-92-1.png" width="672" /></p>
<p>In case of the Half-Normal distance function,
<span class="math inline">\(\tau\)</span> is the <em>effective detection radius</em> (EDR).
The effective detection radius is the distance from observer
where the number of individuals missed within EDR
(volume of ‘air’ in the cookie cutter above the dough)
equals the number of individuals detected outside of EDR
(dough volume outside the cookie cutter),
EDR is the radius <span class="math inline">\(r_e\)</span> where <span class="math inline">\(q(r_e)=\pi(r_e)\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="dv">0</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>, <span class="dt">xlim=</span>m<span class="op">*</span><span class="kw">c</span>(<span class="op">-</span>rmax, rmax), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="op">-</span>w, <span class="dv">1</span><span class="op">+</span>w), 
  <span class="dt">axes=</span><span class="ot">FALSE</span>, <span class="dt">ann=</span><span class="ot">FALSE</span>)
yh &lt;-<span class="st"> </span><span class="kw">g</span>(rmax, <span class="dt">tau=</span>tau)
<span class="kw">lines</span>(<span class="kw">seq</span>(<span class="op">-</span>m<span class="op">*</span>rmax, m<span class="op">*</span>rmax, rmax<span class="op">/</span>(m<span class="op">*</span><span class="dv">100</span>)),
  <span class="kw">g</span>(<span class="kw">seq</span>(<span class="op">-</span>m<span class="op">*</span>rmax, m<span class="op">*</span>rmax, rmax<span class="op">/</span>(m<span class="op">*</span><span class="dv">100</span>)), <span class="dt">tau=</span>tau),
  <span class="dt">col=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="kw">seq</span>(<span class="op">-</span>rmax, rmax, rmax<span class="op">/</span><span class="dv">100</span>),
  <span class="kw">g</span>(<span class="kw">abs</span>(<span class="kw">seq</span>(<span class="op">-</span>rmax, rmax, rmax<span class="op">/</span><span class="dv">100</span>)), <span class="dt">tau=</span>tau))
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, yh, rmax, w, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="op">-</span><span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(<span class="dv">0</span>, yh))
<span class="kw">lines</span>(<span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(<span class="dv">0</span>, yh))
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, <span class="dv">0</span>, rmax, w)
<span class="kw">draw_ellipse</span>(<span class="dv">0</span>, <span class="dv">1</span>, rmax, w, <span class="dt">border=</span><span class="dv">4</span>)
<span class="kw">lines</span>(<span class="op">-</span><span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(yh, <span class="dv">1</span>), <span class="dt">col=</span><span class="dv">4</span>)
<span class="kw">lines</span>(<span class="kw">c</span>(rmax, rmax), <span class="kw">c</span>(yh, <span class="dv">1</span>), <span class="dt">col=</span><span class="dv">4</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-93-1.png" width="672" /></p>

<div class="rmdexercise">
<p><strong>Exercise</strong></p>
<p>What would be a computational algorithm to calculate EDR
for any distance function and truncation distance?</p>
<p>Trye to explain how the code below is working.</p>
Why are EDRs different for different truncation distances?
</div>

<pre class="sourceCode r"><code class="sourceCode r">find_edr &lt;-<span class="st"> </span><span class="cf">function</span>(dist_fun, ..., <span class="dt">rmax=</span><span class="ot">Inf</span>) {
  <span class="co">## integral function</span>
  f &lt;-<span class="st"> </span><span class="cf">function</span>(d, ...)
    <span class="kw">dist_fun</span>(d, ...) <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>d<span class="op">*</span>pi
  <span class="co">## volume under dist_fun</span>
  V &lt;-<span class="st"> </span><span class="kw">integrate</span>(f, <span class="dt">lower=</span><span class="dv">0</span>, <span class="dt">upper=</span>rmax, ...)<span class="op">$</span>value
  u &lt;-<span class="st"> </span><span class="cf">function</span>(edr)
    V <span class="op">-</span><span class="st"> </span>edr<span class="op">^</span><span class="dv">2</span><span class="op">*</span>pi
  <span class="kw">uniroot</span>(u, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1000</span>))<span class="op">$</span>root
}

<span class="kw">find_edr</span>(g, <span class="dt">tau=</span><span class="dv">1</span>)</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">find_edr</span>(g, <span class="dt">tau=</span><span class="dv">10</span>)</code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">find_edr</span>(g, <span class="dt">tau=</span><span class="dv">1</span>, <span class="dt">b=</span><span class="dv">1</span>)</code></pre>
<pre><code>## [1] 1.414</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">find_edr</span>(g, <span class="dt">tau=</span><span class="dv">1</span>, <span class="dt">b=</span><span class="dv">4</span>, <span class="dt">hazard=</span><span class="ot">TRUE</span>)</code></pre>
<pre><code>## [1] 1.331</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">find_edr</span>(g, <span class="dt">tau=</span><span class="dv">1</span>, <span class="dt">rmax=</span><span class="dv">1</span>)</code></pre>
<pre><code>## [1] 0.7951</code></pre>
<p>The function <span class="math inline">\(\pi(r)\)</span> increases monotonically from 0 to 1:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(x<span class="op">/</span>tau)<span class="op">^</span><span class="dv">2</span>), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">col=</span><span class="dv">4</span>,
  <span class="dt">ylab=</span><span class="kw">expression</span>(<span class="kw">pi</span>(d)), <span class="dt">xlab=</span><span class="kw">expression</span>(d), 
  <span class="dt">main=</span><span class="st">&quot;Cumulative density&quot;</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
<p>Here are binned distances for the bSims data, with expected
proportions based on <span class="math inline">\(\pi()\)</span> cell probabilities
(differences within the distance bins).
The nice thing about this cumulative density formulation
is that it applies equally to truncated and unlimited
(not truncated) distance data, and the radius end point
for a bin (stored in <code>br</code>) can be infinite:</p>
<pre class="sourceCode r"><code class="sourceCode r">br &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="ot">Inf</span>)
dat<span class="op">$</span>bin &lt;-<span class="st"> </span><span class="kw">cut</span>(da, <span class="kw">c</span>(<span class="dv">0</span>, br), <span class="dt">include.lowest =</span> <span class="ot">TRUE</span>)
(counts &lt;-<span class="st"> </span><span class="kw">with</span>(dat, <span class="kw">table</span>(bin, detected)))</code></pre>
<pre><code>##          detected
## bin         0   1
##   [0,1]     7  27
##   (1,2]    42  53
##   (2,3]   111  32
##   (3,4]   227  13
##   (4,5]   287   2
##   (5,Inf] 211   1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">pi_br &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(br<span class="op">/</span>tau)<span class="op">^</span><span class="dv">2</span>)

<span class="kw">barplot</span>(counts[,<span class="st">&quot;1&quot;</span>]<span class="op">/</span><span class="kw">sum</span>(counts[,<span class="st">&quot;1&quot;</span>]), <span class="dt">space=</span><span class="dv">0</span>, <span class="dt">col=</span><span class="ot">NA</span>,
  <span class="dt">xlab=</span><span class="st">&quot;Distance bins (100 m)&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Proportions&quot;</span>)
<span class="kw">lines</span>(<span class="kw">seq_len</span>(<span class="kw">length</span>(br))<span class="op">-</span><span class="fl">0.5</span>, <span class="kw">diff</span>(<span class="kw">c</span>(<span class="dv">0</span>, pi_br)), <span class="dt">col=</span><span class="dv">3</span>)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
<p>We can use the <code>bsims_transcribe</code> function for the same effect,
and estimate <span class="math inline">\(\hat{\tau}\)</span> based on the binned data:</p>
<pre class="sourceCode r"><code class="sourceCode r">(tr &lt;-<span class="st"> </span><span class="kw">bsims_transcribe</span>(o, <span class="dt">rint=</span>br))</code></pre>
<pre><code>## bSims transcript
##   1 km x 1 km
##   stratification: H
##   total abundance: 1013
##   no events, duration: 10 min
##   detected: 128 seen/heard
##   1st event detected by bins:
##     [0-10 min]
##     [0-100, 100-200, 200-300, 300-400, 400-500, 500+ m]</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">tr<span class="op">$</span>removal</code></pre>
<pre><code>##          0-10min
## 0-100m        27
## 100-200m      53
## 200-300m      32
## 300-400m      13
## 400-500m       2
## 500+m          1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">Y &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">drop</span>(tr<span class="op">$</span>removal), <span class="dt">nrow=</span><span class="dv">1</span>)
D &lt;-<span class="st"> </span><span class="kw">matrix</span>(br, <span class="dt">nrow=</span><span class="dv">1</span>)

tauhat &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">cmulti.fit</span>(Y, D, <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)<span class="op">$</span>coef)

<span class="kw">c</span>(<span class="dt">true=</span>tau, <span class="dt">estimate=</span>tauhat)</code></pre>
<pre><code>##     true estimate 
##    2.000    2.067</code></pre>
<p>Here are cumulative counts and the true end expected
cumulative cell probabilities:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">stepfun</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">cumsum</span>(counts[,<span class="st">&quot;1&quot;</span>])<span class="op">/</span><span class="kw">sum</span>(counts[,<span class="st">&quot;1&quot;</span>]))), 
  <span class="dt">do.points=</span><span class="ot">FALSE</span>, <span class="dt">main=</span><span class="st">&quot;Binned CDF&quot;</span>,
  <span class="dt">ylab=</span><span class="st">&quot;Cumulative probability&quot;</span>, 
  <span class="dt">xlab=</span><span class="st">&quot;Bin radius end point (100 m)&quot;</span>)
<span class="kw">curve</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(x<span class="op">/</span>tau)<span class="op">^</span><span class="dv">2</span>), <span class="dt">col=</span><span class="dv">2</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(x<span class="op">/</span>tauhat)<span class="op">^</span><span class="dv">2</span>), <span class="dt">col=</span><span class="dv">4</span>, <span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>), 
  <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;True&quot;</span>, <span class="st">&quot;Estimated&quot;</span>, <span class="st">&quot;Empirical&quot;</span>))</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-99-1.png" width="672" /></p>
</div>
<div id="availability-bias" class="section level2">
<h2><span class="header-section-number">5.7</span> Availability bias</h2>
<p>We have ignored availability so far when working with bSims,
but can’t continue like that for real data.
What this means, is that <span class="math inline">\(g(0) &lt; 1\)</span>, so detecting
an individual 0 distance from the observer depends on
an event (visual or auditory) that would trigger the detection.
For example, if a perfecly camouflaged birds sits in silence,
detection might be difficult. Movement, or a vocalization
can, however, reveal the individual and its location.</p>
<p>The <code>phi</code> and <code>tau</code> values are at the high end of plausible
values for songbirds. The <code>Den</code>sity value is exaggerated,
but this way we will have enough counts to prove our points
using bSims:</p>
<pre class="sourceCode r"><code class="sourceCode r">phi &lt;-<span class="st"> </span><span class="fl">0.5</span>
tau &lt;-<span class="st"> </span><span class="dv">2</span>
Den &lt;-<span class="st"> </span><span class="dv">10</span></code></pre>
<p>Now we go through the layers of our bSims world:</p>
<ol style="list-style-type: decimal">
<li>initiating the landscape,</li>
<li>populating the landscape by individuals,</li>
<li>breath life into the virtual birds and let them sing,</li>
<li>put in an observer and let the observation process begin.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2</span>)
l &lt;-<span class="st"> </span><span class="kw">bsims_init</span>()
a &lt;-<span class="st"> </span><span class="kw">bsims_populate</span>(l, <span class="dt">density=</span>Den)
b &lt;-<span class="st"> </span><span class="kw">bsims_animate</span>(a, <span class="dt">vocal_rate=</span>phi)
o &lt;-<span class="st"> </span><span class="kw">bsims_detect</span>(b, <span class="dt">tau=</span>tau)</code></pre>
<p>Transcription is the process of turning the detections
into a table showing new individuals detected by
time intervals and distance bands, as defined
by the <code>tint</code> and <code>rint</code> arguments, respectively.</p>
<pre class="sourceCode r"><code class="sourceCode r">tint &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)
rint &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">1.5</span>, <span class="dv">2</span>) <span class="co"># truncated at 200 m</span>
(tr &lt;-<span class="st"> </span><span class="kw">bsims_transcribe</span>(o, <span class="dt">tint=</span>tint, <span class="dt">rint=</span>rint))</code></pre>
<pre><code>## bSims transcript
##   1 km x 1 km
##   stratification: H
##   total abundance: 957
##   duration: 10 min
##   detected: 282 heard
##   1st event detected by bins:
##     [0-1, 1-2, 2-3, 3-4, 4-5 min]
##     [0-50, 50-100, 100-150, 150-200 m]</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(rem &lt;-<span class="st"> </span>tr<span class="op">$</span>removal) <span class="co"># binned new individuals</span></code></pre>
<pre><code>##          0-1min 1-2min 2-3min 3-4min 4-5min
## 0-50m         1      4      0      2      0
## 50-100m       4      6      2      4      1
## 100-150m     13      5      6      4      2
## 150-200m     13      5      2      7      3</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colSums</span>(rem)</code></pre>
<pre><code>## 0-1min 1-2min 2-3min 3-4min 4-5min 
##     31     20     10     17      6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rowSums</span>(rem)</code></pre>
<pre><code>##    0-50m  50-100m 100-150m 150-200m 
##        7       17       30       30</code></pre>
<p>The plot method displays the detections presented as part of the <code>tr</code> object.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(tr)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-103-1.png" width="768" /></p>
<p>The detection process and the transcription (following a prescribed
protocol) is inseparable in the field. However, recordings
made in the field can be processed by a number of different ways.
Separating these processed gives the ability to make these
conparisons on the exact same set of detections.</p>
</div>
<div id="estimating-density-with-truncation" class="section level2">
<h2><span class="header-section-number">5.8</span> Estimating density with truncation</h2>
<p>We now fit the removal model to the data pooled by time intervals.
<code>p</code> is the cumulative probability of availability for the total duration:</p>
<pre class="sourceCode r"><code class="sourceCode r">fitp &lt;-<span class="st"> </span><span class="kw">cmulti.fit</span>(<span class="kw">matrix</span>(<span class="kw">colSums</span>(rem), <span class="dv">1</span>), <span class="kw">matrix</span>(tint, <span class="dv">1</span>), <span class="dt">type=</span><span class="st">&quot;rem&quot;</span>)
phihat &lt;-<span class="st"> </span><span class="kw">exp</span>(fitp<span class="op">$</span>coef)
<span class="kw">c</span>(<span class="dt">true=</span>phi, <span class="dt">estimate=</span><span class="kw">exp</span>(fitp<span class="op">$</span>coef))</code></pre>
<pre><code>##     true estimate 
##   0.5000   0.3301</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(p &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="kw">max</span>(tint)<span class="op">*</span>phihat))</code></pre>
<pre><code>## [1] 0.8081</code></pre>
<p>The distance sampling model uses the distance binned counts,
and a Half-Normal detection function, <code>q</code> is the cumulative
probability of perceptibility within the area of
truncation distance <code>rmax</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">fitq &lt;-<span class="st"> </span><span class="kw">cmulti.fit</span>(<span class="kw">matrix</span>(<span class="kw">rowSums</span>(rem), <span class="dv">1</span>), <span class="kw">matrix</span>(rint, <span class="dv">1</span>), <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)
tauhat &lt;-<span class="st"> </span><span class="kw">exp</span>(fitq<span class="op">$</span>coef)
<span class="kw">c</span>(<span class="dt">true=</span>tau, <span class="dt">estimate=</span>tauhat)</code></pre>
<pre><code>##     true estimate 
##    2.000    2.659</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">rmax &lt;-<span class="st"> </span><span class="kw">max</span>(rint)
(q &lt;-<span class="st"> </span>(tauhat<span class="op">^</span><span class="dv">2</span><span class="op">/</span>rmax<span class="op">^</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(rmax<span class="op">/</span>tauhat)<span class="op">^</span><span class="dv">2</span>)))</code></pre>
<pre><code>## [1] 0.7638</code></pre>
<p>The known <code>A</code>rea, <code>p</code>, and <code>q</code> makes up the correction factor,
which is used to estimate density based on <span class="math inline">\(\hat{D}=Y/(A \hat{p}\hat{q})\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">(A &lt;-<span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>rmax<span class="op">^</span><span class="dv">2</span>)</code></pre>
<pre><code>## [1] 12.57</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">Dhat &lt;-<span class="st"> </span><span class="kw">sum</span>(rem) <span class="op">/</span><span class="st"> </span>(A <span class="op">*</span><span class="st"> </span>p <span class="op">*</span><span class="st"> </span>q)
<span class="kw">c</span>(<span class="dt">true=</span>Den, <span class="dt">estimate=</span>Dhat)</code></pre>
<pre><code>##     true estimate 
##    10.00    10.83</code></pre>
</div>
<div id="unlimited-distance" class="section level2">
<h2><span class="header-section-number">5.9</span> Unlimited distance</h2>
<p>We now change the distance bins to include the area outside of the
previous <code>rmax</code> distance, making the counts unlimited distance counts:</p>
<pre class="sourceCode r"><code class="sourceCode r">rint &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">1.5</span>, <span class="dv">2</span>, <span class="ot">Inf</span>) <span class="co"># unlimited</span>

(tr &lt;-<span class="st"> </span><span class="kw">bsims_transcribe</span>(o, <span class="dt">tint=</span>tint, <span class="dt">rint=</span>rint))</code></pre>
<pre><code>## bSims transcript
##   1 km x 1 km
##   stratification: H
##   total abundance: 957
##   duration: 10 min
##   detected: 282 heard
##   1st event detected by bins:
##     [0-1, 1-2, 2-3, 3-4, 4-5 min]
##     [0-50, 50-100, 100-150, 150-200, 200+ m]</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(rem &lt;-<span class="st"> </span>tr<span class="op">$</span>removal) <span class="co"># binned new individuals</span></code></pre>
<pre><code>##          0-1min 1-2min 2-3min 3-4min 4-5min
## 0-50m         1      4      0      2      0
## 50-100m       4      6      2      4      1
## 100-150m     13      5      6      4      2
## 150-200m     13      5      2      7      3
## 200+m        23     13      7      3      2</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colSums</span>(rem)</code></pre>
<pre><code>## 0-1min 1-2min 2-3min 3-4min 4-5min 
##     54     33     17     20      8</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rowSums</span>(rem)</code></pre>
<pre><code>##    0-50m  50-100m 100-150m 150-200m    200+m 
##        7       17       30       30       48</code></pre>
<p>The removal model is basically the same, the only
difference is that the counts can be higher due to
detecting over larger area and thus potentially
detecting more individuals:</p>
<pre class="sourceCode r"><code class="sourceCode r">fitp &lt;-<span class="st"> </span><span class="kw">cmulti.fit</span>(<span class="kw">matrix</span>(<span class="kw">colSums</span>(rem), <span class="dv">1</span>), <span class="kw">matrix</span>(tint, <span class="dv">1</span>), <span class="dt">type=</span><span class="st">&quot;rem&quot;</span>)
phihat &lt;-<span class="st"> </span><span class="kw">exp</span>(fitp<span class="op">$</span>coef)
<span class="kw">c</span>(<span class="dt">true=</span>phi, <span class="dt">estimate=</span>phihat)</code></pre>
<pre><code>##     true estimate 
##   0.5000   0.4285</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(p &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="kw">max</span>(tint)<span class="op">*</span>phihat))</code></pre>
<pre><code>## [1] 0.8826</code></pre>
<p>The diatance sampling model also takes the extended data set.</p>
<pre class="sourceCode r"><code class="sourceCode r">fitq &lt;-<span class="st"> </span><span class="kw">cmulti.fit</span>(<span class="kw">matrix</span>(<span class="kw">rowSums</span>(rem), <span class="dv">1</span>), <span class="kw">matrix</span>(rint, <span class="dv">1</span>), <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)
tauhat &lt;-<span class="st"> </span><span class="kw">exp</span>(fitq<span class="op">$</span>coef)
<span class="kw">c</span>(<span class="dt">true=</span>tau, <span class="dt">estimate=</span>tauhat)</code></pre>
<pre><code>##     true estimate 
##    2.000    2.021</code></pre>
<p>The problem is that our truncation distance is infinite,
thus the area that we are sampling is also infinite.
This does not make too much sense, and not at all hepful
in estimating density (anything divided by infinity is 0).
So we use EDR (<code>tauhat</code> for Half-Normal) and calculate
the estimated effective area sampled (<code>Ahat</code>; <span class="math inline">\(\hat{A}=\pi \hat{\tau}^2\)</span>).
We also set <code>q</code> to be 1, because the logic behind EDR is that its
volume equals the volume of the integral, in other words,
it is an area that would give on average same count under perfect detection
Finally, we estimate density using <span class="math inline">\(\hat{D}=Y/(\hat{A} \hat{p}1)\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">(Ahat &lt;-<span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>tauhat<span class="op">^</span><span class="dv">2</span>)</code></pre>
<pre><code>## [1] 12.83</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">q &lt;-<span class="st"> </span><span class="dv">1</span>

Dhat &lt;-<span class="st"> </span><span class="kw">sum</span>(rem) <span class="op">/</span><span class="st"> </span>(Ahat <span class="op">*</span><span class="st"> </span>p <span class="op">*</span><span class="st"> </span>q)
<span class="kw">c</span>(<span class="dt">true=</span>Den, <span class="dt">estimate=</span>Dhat)</code></pre>
<pre><code>##     true estimate 
##    10.00    11.66</code></pre>
</div>
<div id="replicating-landscapes" class="section level2">
<h2><span class="header-section-number">5.10</span> Replicating landscapes</h2>
<p>Remember, that we have used so far a single location.
We set the density unreasonably high to have enough counts
for a reasonable estimate.
We can independently replicate the simulation for multiple
landscapes and analyze the results to give justice to bSims
under idealized conditions:</p>
<pre class="sourceCode r"><code class="sourceCode r">phi &lt;-<span class="st"> </span><span class="fl">0.5</span>
tau &lt;-<span class="st"> </span><span class="dv">1</span>
Den &lt;-<span class="st"> </span><span class="dv">1</span>

tint &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>)
rint &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">1.5</span>, <span class="ot">Inf</span>)

sim_fun &lt;-<span class="st"> </span><span class="cf">function</span>() {
  l &lt;-<span class="st"> </span><span class="kw">bsims_init</span>()
  a &lt;-<span class="st"> </span><span class="kw">bsims_populate</span>(l, <span class="dt">density=</span>Den)
  b &lt;-<span class="st"> </span><span class="kw">bsims_animate</span>(a, <span class="dt">vocal_rate=</span>phi)
  o &lt;-<span class="st"> </span><span class="kw">bsims_detect</span>(b, <span class="dt">tau=</span>tau)
  <span class="kw">bsims_transcribe</span>(o, <span class="dt">tint=</span>tint, <span class="dt">rint=</span>rint)<span class="op">$</span>rem
}

B &lt;-<span class="st"> </span><span class="dv">200</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
res &lt;-<span class="st"> </span>pbapply<span class="op">::</span><span class="kw">pbreplicate</span>(B, <span class="kw">sim_fun</span>(), <span class="dt">simplify=</span><span class="ot">FALSE</span>)

Ddur &lt;-<span class="st"> </span><span class="kw">matrix</span>(tint, B, <span class="kw">length</span>(tint), <span class="dt">byrow=</span><span class="ot">TRUE</span>)
Ydur1 &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(res, <span class="cf">function</span>(z) <span class="kw">colSums</span>(z)))
Ydur2 &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(res, <span class="cf">function</span>(z) <span class="kw">colSums</span>(z[<span class="op">-</span><span class="kw">nrow</span>(z),])))
<span class="kw">colSums</span>(Ydur1) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(Ydur1)
<span class="kw">colSums</span>(Ydur2) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(Ydur2)
fitp1 &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydur1 <span class="op">|</span><span class="st"> </span>Ddur <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">type=</span><span class="st">&quot;rem&quot;</span>)
fitp2 &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydur2 <span class="op">|</span><span class="st"> </span>Ddur <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">type=</span><span class="st">&quot;rem&quot;</span>)
phihat1 &lt;-<span class="st"> </span><span class="kw">unname</span>(<span class="kw">exp</span>(<span class="kw">coef</span>(fitp1)))
phihat2 &lt;-<span class="st"> </span><span class="kw">unname</span>(<span class="kw">exp</span>(<span class="kw">coef</span>(fitp2)))

Ddis1 &lt;-<span class="st"> </span><span class="kw">matrix</span>(rint, B, <span class="kw">length</span>(rint), <span class="dt">byrow=</span><span class="ot">TRUE</span>)
Ddis2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(rint[<span class="op">-</span><span class="kw">length</span>(rint)], B, <span class="kw">length</span>(rint)<span class="op">-</span><span class="dv">1</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)
Ydis1 &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(res, <span class="cf">function</span>(z) <span class="kw">rowSums</span>(z)))
Ydis2 &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(res, <span class="cf">function</span>(z) <span class="kw">rowSums</span>(z)[<span class="op">-</span><span class="kw">length</span>(rint)]))
<span class="kw">colSums</span>(Ydis1) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(Ydis1)
<span class="kw">colSums</span>(Ydis2) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(Ydis2)
fitq1 &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydis1 <span class="op">|</span><span class="st"> </span>Ddis1 <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)
fitq2 &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydis2 <span class="op">|</span><span class="st"> </span>Ddis2 <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)
tauhat1 &lt;-<span class="st"> </span><span class="kw">unname</span>(<span class="kw">exp</span>(fitq1<span class="op">$</span>coef))
tauhat2 &lt;-<span class="st"> </span><span class="kw">unname</span>(<span class="kw">exp</span>(fitq2<span class="op">$</span>coef))

<span class="co">## unlimited correction</span>
Apq1 &lt;-<span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>tauhat1<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="kw">max</span>(tint)<span class="op">*</span>phihat1)) <span class="op">*</span><span class="st"> </span><span class="dv">1</span>
rmax &lt;-<span class="st"> </span><span class="kw">max</span>(rint[<span class="kw">is.finite</span>(rint)])
<span class="co">## truncated correction</span>
Apq2 &lt;-<span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>rmax<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="kw">max</span>(tint)<span class="op">*</span>phihat2)) <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>(tauhat2<span class="op">^</span><span class="dv">2</span><span class="op">/</span>rmax<span class="op">^</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>(rmax<span class="op">/</span>tauhat2)<span class="op">^</span><span class="dv">2</span>))

<span class="kw">round</span>(<span class="kw">rbind</span>(
  <span class="dt">phi=</span><span class="kw">c</span>(<span class="dt">true=</span>phi, <span class="dt">unlimited=</span>phihat1, <span class="dt">truncated=</span>phihat2),
  <span class="dt">tau=</span><span class="kw">c</span>(<span class="dt">true=</span>tau, <span class="dt">unlimited=</span>tauhat1, <span class="dt">truncated=</span>tauhat2),
  <span class="dt">D=</span><span class="kw">c</span>(Den, <span class="dt">unlimited=</span><span class="kw">mean</span>(<span class="kw">rowSums</span>(Ydis1))<span class="op">/</span>Apq1,
      <span class="dt">truncated=</span><span class="kw">mean</span>(<span class="kw">rowSums</span>(Ydis2))<span class="op">/</span>Apq2)), <span class="dv">4</span>)
<span class="co">##     true unlimited truncated</span>
<span class="co">## phi  0.5    0.4835    0.4852</span>
<span class="co">## tau  1.0    1.0002    0.9681</span>
<span class="co">## D    1.0    1.0601    1.1048</span></code></pre>

<div class="rmdexercise">
<p><strong>Exercise</strong></p>
If time permits, try different settings and time/distance intervals.
</div>

</div>
<div id="josm-data" class="section level2">
<h2><span class="header-section-number">5.11</span> JOSM data</h2>
<p>Quickly organize the JOSM data:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## predictors</span>
x &lt;-<span class="st"> </span>josm<span class="op">$</span>surveys
x<span class="op">$</span>FOR &lt;-<span class="st"> </span>x<span class="op">$</span>Decid <span class="op">+</span><span class="st"> </span>x<span class="op">$</span>Conif<span class="op">+</span><span class="st"> </span>x<span class="op">$</span>ConifWet <span class="co"># forest</span>
x<span class="op">$</span>AHF &lt;-<span class="st"> </span>x<span class="op">$</span>Agr <span class="op">+</span><span class="st"> </span>x<span class="op">$</span>UrbInd <span class="op">+</span><span class="st"> </span>x<span class="op">$</span>Roads <span class="co"># &#39;alienating&#39; human footprint</span>
x<span class="op">$</span>WET &lt;-<span class="st"> </span>x<span class="op">$</span>OpenWet <span class="op">+</span><span class="st"> </span>x<span class="op">$</span>ConifWet <span class="op">+</span><span class="st"> </span>x<span class="op">$</span>Water <span class="co"># wet + water</span>
cn &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Open&quot;</span>, <span class="st">&quot;Water&quot;</span>, <span class="st">&quot;Agr&quot;</span>, <span class="st">&quot;UrbInd&quot;</span>, <span class="st">&quot;SoftLin&quot;</span>, <span class="st">&quot;Roads&quot;</span>, <span class="st">&quot;Decid&quot;</span>, 
  <span class="st">&quot;OpenWet&quot;</span>, <span class="st">&quot;Conif&quot;</span>, <span class="st">&quot;ConifWet&quot;</span>)
x<span class="op">$</span>HAB &lt;-<span class="st"> </span><span class="kw">droplevels</span>(<span class="kw">find_max</span>(x[,cn])<span class="op">$</span>index) <span class="co"># drop empty levels</span>
<span class="kw">levels</span>(x<span class="op">$</span>HAB)[<span class="kw">levels</span>(x<span class="op">$</span>HAB) <span class="op">%in%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">c</span>(<span class="st">&quot;OpenWet&quot;</span>, <span class="st">&quot;Water&quot;</span>, <span class="st">&quot;Open&quot;</span>, <span class="st">&quot;Agr&quot;</span>, <span class="st">&quot;UrbInd&quot;</span>, <span class="st">&quot;Roads&quot;</span>)] &lt;-<span class="st"> &quot;Open&quot;</span>
<span class="kw">levels</span>(x<span class="op">$</span>HAB)[<span class="kw">levels</span>(x<span class="op">$</span>HAB) <span class="op">%in%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">c</span>(<span class="st">&quot;Conif&quot;</span>, <span class="st">&quot;ConifWet&quot;</span>)] &lt;-<span class="st"> &quot;Conif&quot;</span>
x<span class="op">$</span>OBS &lt;-<span class="st"> </span><span class="kw">as.factor</span>(x<span class="op">$</span>ObserverID)

<span class="co">## time intervals</span>
yall_dur &lt;-<span class="st"> </span><span class="kw">Xtab</span>(<span class="op">~</span><span class="st"> </span>SiteID <span class="op">+</span><span class="st"> </span>Dur <span class="op">+</span><span class="st"> </span>SpeciesID, 
  josm<span class="op">$</span>counts[josm<span class="op">$</span>counts<span class="op">$</span>DetectType1 <span class="op">!=</span><span class="st"> &quot;V&quot;</span>,])
yall_dur &lt;-<span class="st"> </span>yall_dur[<span class="kw">sapply</span>(yall_dur, <span class="cf">function</span>(z) <span class="kw">sum</span>(<span class="kw">rowSums</span>(z) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">&gt;</span><span class="st"> </span><span class="dv">100</span>]

<span class="co">## distance intervals</span>
yall_dis &lt;-<span class="st"> </span><span class="kw">Xtab</span>(<span class="op">~</span><span class="st"> </span>SiteID <span class="op">+</span><span class="st"> </span>Dis <span class="op">+</span><span class="st"> </span>SpeciesID, 
  josm<span class="op">$</span>counts[josm<span class="op">$</span>counts<span class="op">$</span>DetectType1 <span class="op">!=</span><span class="st"> &quot;V&quot;</span>,])
yall_dis &lt;-<span class="st"> </span>yall_dis[<span class="kw">sapply</span>(yall_dis, <span class="cf">function</span>(z) <span class="kw">sum</span>(<span class="kw">rowSums</span>(z) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">&gt;</span><span class="st"> </span><span class="dv">100</span>]</code></pre>
<p>Pick our most abundant species again, and organize the data:</p>
<pre class="sourceCode r"><code class="sourceCode r">spp &lt;-<span class="st"> &quot;TEWA&quot;</span>

Ydur &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(yall_dur[[spp]])
Ddur &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>), <span class="kw">nrow</span>(Ydur), <span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>,
  <span class="dt">dimnames=</span><span class="kw">dimnames</span>(Ydur))
<span class="kw">stopifnot</span>(<span class="kw">all</span>(<span class="kw">rownames</span>(x) <span class="op">==</span><span class="st"> </span><span class="kw">rownames</span>(Ydur)))

Ydis &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(yall_dis[[spp]])
Ddis &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="ot">Inf</span>), <span class="kw">nrow</span>(Ydis), <span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>,
  <span class="dt">dimnames=</span><span class="kw">dimnames</span>(Ydis))
<span class="kw">stopifnot</span>(<span class="kw">all</span>(<span class="kw">rownames</span>(x) <span class="op">==</span><span class="st"> </span><span class="kw">rownames</span>(Ydis)))

<span class="kw">colSums</span>(Ydur)</code></pre>
<pre><code>##  0-3min  3-5min 5-10min 
##    4262     558     764</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colSums</span>(Ydis)</code></pre>
<pre><code>##   0-50m 50-100m   100+m 
##    2703    2470     411</code></pre>
<p>We pick a removal models with <code>DAY</code> as covariate,
and calculate <span class="math inline">\(p(t)\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">Mdur &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydur <span class="op">|</span><span class="st"> </span>Ddur <span class="op">~</span><span class="st"> </span>DAY, x, <span class="dt">type=</span><span class="st">&quot;rem&quot;</span>)
<span class="kw">summary</span>(Mdur)</code></pre>
<pre><code>## 
## Call:
## cmulti(formula = Ydur | Ddur ~ DAY, data = x, type = &quot;rem&quot;)
## 
## Removal Sampling (homogeneous singing rate)
## Conditional Maximum Likelihood estimates
## 
## Coefficients:
##                     Estimate Std. Error z value Pr(&gt;|z|)    
## log.phi_(Intercept)   0.0784     0.2615    0.30  0.76427    
## log.phi_DAY          -2.0910     0.5866   -3.56  0.00036 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Log-likelihood: -3.2e+03 
## BIC = 6.41e+03</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">phi &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">model.matrix</span>(Mdur) <span class="op">%*%</span><span class="st"> </span><span class="kw">coef</span>(Mdur))
<span class="kw">summary</span>(phi)</code></pre>
<pre><code>##        V1       
##  Min.   :0.377  
##  1st Qu.:0.402  
##  Median :0.420  
##  Mean   :0.423  
##  3rd Qu.:0.448  
##  Max.   :0.477</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">10</span><span class="op">*</span>phi)</code></pre>
<p>We fit the intercept only distance sampling model next:</p>
<pre class="sourceCode r"><code class="sourceCode r">Mdis0 &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydis <span class="op">|</span><span class="st"> </span>Ddis <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, x, <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)
<span class="kw">summary</span>(Mdis0)</code></pre>
<pre><code>## 
## Call:
## cmulti(formula = Ydis | Ddis ~ 1, data = x, type = &quot;dis&quot;)
## 
## Distance Sampling (half-normal, circular area)
## Conditional Maximum Likelihood estimates
## 
## Coefficients:
##                     Estimate Std. Error z value Pr(&gt;|z|)    
## log.tau_(Intercept) -0.48272    0.00753   -64.1   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Log-likelihood: -3.82e+03 
## BIC = 7.65e+03</code></pre>
<p>Let’s try a few covariates:</p>
<ul>
<li>continuous <code>FOR</code>est cover covariate: sound attenuation increases with forest cover;</li>
<li>discrete <code>HAB</code>itat has 3 levels: open, deciduous forest, and coniferous forest (based on dominant land cover), because broad leaves and needles affect sound attenuation;</li>
<li>finally, we use observer ID as categorical variable: observers might have different hearing abilities, training/experiance levels, good times, bad times, etc.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">Mdis1 &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydis <span class="op">|</span><span class="st"> </span>Ddis <span class="op">~</span><span class="st"> </span>FOR, x, <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)
Mdis2 &lt;-<span class="st"> </span><span class="kw">cmulti</span>(Ydis <span class="op">|</span><span class="st"> </span>Ddis <span class="op">~</span><span class="st"> </span>HAB, x, <span class="dt">type=</span><span class="st">&quot;dis&quot;</span>)</code></pre>
<p>We can look at AIC to find the best supported model:</p>
<pre class="sourceCode r"><code class="sourceCode r">aic &lt;-<span class="st"> </span><span class="kw">AIC</span>(Mdis0, Mdis1, Mdis2)
aic<span class="op">$</span>delta_AIC &lt;-<span class="st"> </span>aic<span class="op">$</span>AIC <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(aic<span class="op">$</span>AIC)
aic[<span class="kw">order</span>(aic<span class="op">$</span>AIC),]

Mdis &lt;-<span class="st"> </span><span class="kw">get</span>(<span class="kw">rownames</span>(aic)[aic<span class="op">$</span>delta_AIC <span class="op">==</span><span class="st"> </span><span class="dv">0</span>])
<span class="kw">summary</span>(Mdis)</code></pre>
<pre><code>## 
## Call:
## cmulti(formula = Ydis | Ddis ~ HAB, data = x, type = &quot;dis&quot;)
## 
## Distance Sampling (half-normal, circular area)
## Conditional Maximum Likelihood estimates
## 
## Coefficients:
##                     Estimate Std. Error z value Pr(&gt;|z|)    
## log.tau_(Intercept)  -0.4497     0.0321  -14.02   &lt;2e-16 ***
## log.tau_HABDecid     -0.0583     0.0336   -1.73    0.083 .  
## log.tau_HABConif     -0.0030     0.0343   -0.09    0.930    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Log-likelihood: -3.82e+03 
## BIC = 7.66e+03</code></pre>

<div class="rmdexercise">
<p><strong>Exercise</strong></p>
<p>Use <code>OBS</code> as predictor for <code>tau</code> and look at predicted EDRs.</p>
What is the practical issue with using observer as predictor?
</div>

<p>After finding the best model, we predict <code>tau</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">tau &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">model.matrix</span>(Mdis) <span class="op">%*%</span><span class="st"> </span><span class="kw">coef</span>(Mdis))
<span class="kw">boxplot</span>(tau <span class="op">~</span><span class="st"> </span>HAB, x)</code></pre>
<p><img src="qpad-book_files/figure-html/unnamed-chunk-120-1.png" width="672" /></p>
<p>Finally, we calculate the correction factor for unlimited distances,
and predict mean density:</p>
<pre class="sourceCode r"><code class="sourceCode r">Apq &lt;-<span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>p <span class="op">*</span><span class="st"> </span><span class="dv">1</span>
x<span class="op">$</span>ytot &lt;-<span class="st"> </span><span class="kw">rowSums</span>(Ydur)
<span class="kw">mean</span>(x<span class="op">$</span>ytot <span class="op">/</span><span class="st"> </span>Apq)</code></pre>
<pre><code>## [1] 1.039</code></pre>
<p>Alternatively, we can use the log of the correction
as an offset in log-linear models. This offset is
called the QPAD offset:</p>
<pre class="sourceCode r"><code class="sourceCode r">off &lt;-<span class="st"> </span><span class="kw">log</span>(Apq)
m &lt;-<span class="st"> </span><span class="kw">glm</span>(ytot <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>x, <span class="dt">offset=</span>off, <span class="dt">family=</span>poisson)
<span class="kw">exp</span>(<span class="kw">coef</span>(m))</code></pre>
<pre><code>## (Intercept) 
##       1.025</code></pre>

<div class="rmdexercise">
<p><strong>Exercise</strong></p>
<p>Try distance sampling and density estimation for another species.</p>
Fit multiple GLMs with QPAD offsets and covariates affecting density,
interpret the results and the visualize responses.
</div>

<p>Sometimes, a recording is made at the survey location
that is listened to and transcribed in the lab
using headphones and possibly a computer screen.
This presents new challenges, and also new opportunities
for analysis of count data – and is the topic of the next chapter.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="behavior.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="recordings.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/psolymos/qpad-book/edit/master/05-detection.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["qpad-book.pdf", "qpad-book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
