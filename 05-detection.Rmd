# The Detection Process {#detection}

## Introduction

As part of the detection process, a skilled observer
counts individual birds at a count station.
New individuals are assigned to time and distance categories,
the type of behavior also registered.
During this process, auditory cues travel through
the distance between the bird and the observer.
As the pover of the sound fades away, the
chanches of being detected also decreases.
If the detection process is based on visual detections,
vegetation can block line of sight, etc.
In this chapter, we scrutinize how this detection process
contributes to the factor $C$.

## Prerequisites

```{r det-libs,message=FALSE,warning=FALSE}
library(bSims)                # simulations
library(detect)               # multinomial models
library(Distance)             # distance sampling
load("_data/josm/josm.rda")   # JOSM data
source("functions.R")         # some useful stuff
```


## Distance functions

The distance function ($g(r)$ describes the probability of detecting an individual
given the distance between the observer and the individual ($r$).
The detection itself is often triggered by visual or auditory cues,
and thus depend on the individuals being available for detection 
(and of course being present in the survey area).

Distance functions have some characteristics:

- It is a monotonic decreasing function of distance,
- $g(0)=1$: detection at 0 distance is perfect.

Here are some common distance function and rationale for their use
(i.e. mechanisms leading to such distance shapes):

1. Negative Exponential: a one-parameter function ($g(r) = e^{-r/\tau}$), probability quickly decreases with distance, this mirrors sound attenuation under spherical spreading, so might be a suitable form for acoustic recoding devices (we will revisit this later), but not a very useful form for human based counts, as explained below;
2. Half-Normal: this is also a one-parameter function ($g(r) = e^{-(r/\tau)^2}$) where probability initially remain high (the _shoulder_), reflecting an increased chance of detecting individuals closer to the observer, this form has also sone practical advantages that we will discuss shortly ($\tau^2$ is variance of the unfolded Normal distribution, $\tau^2/2$ is the variance of the Half-Normal distribution -- both the Negative Exponential and the Half-Normal being special cases of $g(r) = e^{-(r/\tau)^b}$ that have the parameter $b$ [$b > 0$] affecting the shoulder);
3. Hazard rate: this is a two-parameter model ($g(r) = 1-e^{-(r/\tau)^-b}$) that have the parameter $b$ ($b > 0$) affecting the more pronounced and sharp shoulder.


```{r fig.show='hold',out.width='33%'}
r <- seq(0, 2, 0.01)
plot(r, exp(-r/0.8), type="l", col=4, ylim=c(0,1),
  xlab="Distance (100 m)", ylab="P(detection)", main="Negative Exponential")
plot(r, exp(-(r/0.8)^2), type="l", col=4, ylim=c(0,1),
  xlab="Distance (100 m)", ylab="P(detection)", main="Half-Normal")
plot(r, 1-exp(-(r/0.8)^-4), type="l", col=4, ylim=c(0,1),
  xlab="Distance (100 m)", ylab="P(detection)", main="Hazard rate")
```


```{block2, type='rmdexercise'}
**Exercise**

Try different values of $b$ to explore the different shapes of the Hazard rate function.

Write your own code (`plot(r, exp(-(r/<tau>)^<b>), type="l", ylim=c(0,1))`), or run `shiny::runApp("_shiny/distancefun.R")`.
```

We will apply this new found knowledge to our bSims world:
the observer is in the middle of the landscape, and each vocalization
event is aither detected or not, depending on the distance.
Units of `tau` are given on 100 m units, so that corresponding 
density estimates will refer to ha as the unit area.

In this example, we want all individuals to be equally available,
so we are going to override all behavioral aspects of the simulations
by the `initial_location` argument when calling `bsims_animate`.
We set `density` and `tau` high enough to detections in this example.

```{r}
tau <- 2

set.seed(123)
l <- bsims_init()
a <- bsims_populate(l, density=10)
b <- bsims_animate(a, initial_location=TRUE)

(d <- bsims_detect(b, tau=tau, vocal_only=FALSE))
```

```{r fig.width=8,fig.height=8}
plot(d)
```

## Distance sampling

The distribution of the _observed distances_ is a product of detectability
and the distribution of the individuals with respect to the point where
the observer is located.
For point counts, area increases linearly with radial distance, 
implying a triangular distribution with respect to the point
($h(r)=\pi 2 r /A=\pi 2 r / \pi r_{max}^2=2 r / r_{max}^2$, where 
$A$ is a circular survey area with truncation distance $r_{max}$).
The product $g(r) h(r)$ gives the density function of the observed distances.

```{r}
g <- function(r, tau, b=2, hazard=FALSE)
  if (hazard)
    1-exp(-(r/tau)^-b) else exp(-(r/tau)^b)
h <- function(r, rmax)
  2*r/rmax^2
```

```{r fig.show='hold',out.width='33%'}
rmax <- 4

r <- seq(0, rmax, 0.01)
plot(r, g(r, tau), type="l", col=4, ylim=c(0,1),
  xlab="r", ylab="g(r)", main="Prob. of detection")
plot(r, h(r, rmax), type="l", col=4,
  xlab="r", ylab="h(r)", main="PDF of distances")
plot(r, g(r, tau) * h(r, rmax), type="l", col=4,
  xlab="r", ylab="g(r) h(r)", main="Density of observed distances")
```

The object `ra` contains the distances to all the nests
based on our bSims object,
we use this to display the distribution of available distances:

```{r}
ra <- sqrt(rowSums(a$nests[,c("x", "y")]^2))

hist(ra[ra <= rmax], freq=FALSE, xlim=c(0, rmax),
  xlab="Available distances (r <= rmax)", main="")
curve(2*x/rmax^2, add=TRUE, col=2)
```

The `get_detections` function returns a data frame with the
detected events (in our case just the nest locations): 
`$d` is the distance, `$a` is the angle
(in degrees, counter clock-wise from positive x axis).

```{r}
head(dt <- get_detections(d))
```

The following code plots the probability density of the
observed distances within the truncation distance $r_{max}$,
thus we need to standardize the $g(r) h(r)$ function
by the integral sum:

```{r}
f <- function(r, tau, b=2, hazard=FALSE, rmax=1) 
  g(r, tau, b, hazard) * h(r, rmax)
tot <- integrate(f, lower=0, upper=rmax, tau=tau, rmax=rmax)$value

hist(dt$d[dt$d <= rmax], freq=FALSE, xlim=c(0, rmax),
  xlab="Observed distances (r <= rmax)", main="")
curve(f(x, tau=tau, rmax=rmax) / tot, add=TRUE, col=2)
```

In case of the Half-Normal, we can linearize the relationship
by taking the log of the distance function: 
$log(g(r)) =log(e^{-(r/\tau)^2})= -(r / \tau)^2 = x \frac{1}{\tau^2} = 0 + x \beta$.
Consequently, we can use GLM to fit a model with $x = -r^2$ as 
predictor and no intercept, and estimate $\hat{\beta}$ and
$\hat{\tau}=\sqrt{1/\hat{\beta}}$.

For this method to work, we need to know the observed and 
unobserved distances as well,
which makes this approach of low utility in practice when
location of unobserved individuals is unknown.
But we can at least check our bSims data:

```{r}
dat <- data.frame(
  distance=ra, 
  x=-ra^2, 
  detected=ifelse(rownames(d$nests) %in% dt$i, 1, 0))
summary(dat)
mod <- glm(detected ~ x - 1, data=dat, family=binomial(link="log"))
c(true=tau, estimate=sqrt(1/coef(mod)))
```

```{r}
curve(exp(-(x/sqrt(1/coef(mod)))^2), 
  xlim=c(0,max(dat$distance)), ylim=c(0,1),
  xlab="Distance (100 m)", ylab="P(detection)")
curve(exp(-(x/tau)^2), lty=2, add=TRUE)
rug(dat$distance[dat$detected == 0], side=1, col=4)
rug(dat$distance[dat$detected == 1], side=3, col=2)
legend("topright", bty="n", lty=c(2,1), 
  legend=c("True", "Estimated"))

```

The Distance package offers various tools to fit
models to observed distance data. 
See [here](https://workshops.distancesampling.org/duke-spatial-2015/practicals/1-detection-functions-solutions.html) for a tutorial.
The following script fits the Half-Normal (`key = "hn"`)
without ajustments (`adjustment=NULL`) to  
observed distance data from truncated point transect.
It estimates $\sigma = \sqrt{\tau}$:

```{r}
dd <- ds(dt$d, truncation = rmax, transect="point", 
  key = "hn", adjustment=NULL)
c(true=tau, estimate=exp(dd$ddf$par)^2)
```

## Average detection

To calculate the average probability of detecting individuals
within a circle with truncation distance $r_{max}$, we need to
integrate over the product of $g(r)$ and $h(r)$: 
$q(r_{max})=\int_{0}^{r_{max}} g(r) h(r) dr$.
This gives the volume of pie dough cut at $r_{max}$,
compared to the volume of the cookie cutter ($\pi r_{max}^2$).

```{r}
q <- sapply(r[r > 0], function(z)
  integrate(f, lower=0, upper=z, tau=tau, rmax=z)$value)

plot(r, c(1, q), type="l", col=4, ylim=c(0,1),
  xlab=expression(r[max]), ylab=expression(q(r[max])), 
  main="Average prob. of detection")
```

For the Half-Normal detection function, the analytical solution for the 
average probability is 
$\pi \tau^2 [1-exp(-r^2/\tau^2)] / (\pi r_{max}^2)$,
where the denominator is a normalizing constant
representing the volume of a cylinder of perfect detectability.

To visualize this, here is the pie analogy for 
$\tau=2$ and $r_{max}=2$:

```{r}
tau <- 2
rmax <- 2
w <- 0.1
m <- 2
plot(0, type="n", xlim=m*c(-rmax, rmax), ylim=c(-w, 1+w), 
  axes=FALSE, ann=FALSE)
yh <- g(rmax, tau=tau)
lines(seq(-rmax, rmax, rmax/100),
  g(abs(seq(-rmax, rmax, rmax/100)), tau=tau))
draw_ellipse(0, yh, rmax, w, lty=2)
lines(-c(rmax, rmax), c(0, yh))
lines(c(rmax, rmax), c(0, yh))
draw_ellipse(0, 0, rmax, w)
draw_ellipse(0, 1, rmax, w, border=4)
lines(-c(rmax, rmax), c(yh, 1), col=4)
lines(c(rmax, rmax), c(yh, 1), col=4)
```

## Binned distances

The cumulative density function for the Half-Normal
distribution ($\pi(r) = 1-e^{-(r/\tau)^2}$) is used to calculate
cell probabilities for binned distance data
(the normalizing constant is the area of the integral $\pi \tau^2$,
instead of $\pi r_{max}^2$).
It captures the proportion of the observed distances
relative to the whole volume of the observed distance density.
In the pie analogy, this is the dough volume inside
the cookie cutter, compared to the dough volume inside and outside
of the cutter (that happens to be $\pi \tau^2$ for the Half-Normal):

```{r}
plot(0, type="n", xlim=m*c(-rmax, rmax), ylim=c(-w, 1+w), 
  axes=FALSE, ann=FALSE)
yh <- g(rmax, tau=tau)
lines(seq(-m*rmax, m*rmax, rmax/(m*100)),
  g(seq(-m*rmax, m*rmax, rmax/(m*100)), tau=tau),
  col=2)
lines(seq(-rmax, rmax, rmax/100),
  g(abs(seq(-rmax, rmax, rmax/100)), tau=tau))
draw_ellipse(0, yh, rmax, w, lty=2)
lines(-c(rmax, rmax), c(0, yh))
lines(c(rmax, rmax), c(0, yh))
draw_ellipse(0, 0, rmax, w)
```

In case of the Half-Normal distance function,
$\tau$ is the _effective detection radius_ (EDR). 
The effective detection radius is the distance from observer 
where the number of individuals missed within EDR 
(volume of 'air' in the cookie cutter above the dough)
equals the number of individuals detected outside of EDR
(dough volume outside the cookie cutter),
EDR is the radius $r_e$ where $q(r_e)=\pi(r_e)$:

```{r}
plot(0, type="n", xlim=m*c(-rmax, rmax), ylim=c(-w, 1+w), 
  axes=FALSE, ann=FALSE)
yh <- g(rmax, tau=tau)
lines(seq(-m*rmax, m*rmax, rmax/(m*100)),
  g(seq(-m*rmax, m*rmax, rmax/(m*100)), tau=tau),
  col=2)
lines(seq(-rmax, rmax, rmax/100),
  g(abs(seq(-rmax, rmax, rmax/100)), tau=tau))
draw_ellipse(0, yh, rmax, w, lty=2)
lines(-c(rmax, rmax), c(0, yh))
lines(c(rmax, rmax), c(0, yh))
draw_ellipse(0, 0, rmax, w)
draw_ellipse(0, 1, rmax, w, border=4)
lines(-c(rmax, rmax), c(yh, 1), col=4)
lines(c(rmax, rmax), c(yh, 1), col=4)

```

The function $\pi(r)$ increases monotonically from 0 to 1:

```{r}
curve(1-exp(-(x/tau)^2), xlim=c(0, 5), ylim=c(0,1), col=4,
  ylab=expression(pi(r)), xlab=expression(r), 
  main="Cumulative density")
```

Here are binned distances for the bSims data, with expected
proportions based on $\pi()$ cell probabilities 
(differences within the distance bins).
The nice thing about this cumulative density formulation
is that it applies equally to truncated and unlimited
(not truncated) distance data, and the radius end point
for a bin (stored in `br`) can be infinite:

```{r}
br <- c(1, 2, 3, 4, 5, Inf)
dat$bin <- cut(ra, c(0, br), include.lowest = TRUE)
(counts <- with(dat, table(bin, detected)))

pi_br <- 1-exp(-(br/tau)^2)

barplot(counts[,"1"]/sum(counts[,"1"]), space=0, col=NA,
  xlab="Distance bins (100 m)", ylab="Proportions")
lines(seq_len(length(br))-0.5, diff(c(0, pi_br)), col=3)
```

We can use the `bsims_transcribe` function for the same effect,
and estimate $\hat{\tau}$ based on the binned data:

```{r}
(tr <- bsims_transcribe(d, rint=br))
tr$removal

Y <- matrix(drop(tr$removal), nrow=1)
D <- matrix(br, nrow=1)

tauhat <- exp(cmulti.fit(Y, D, type="dis")$coef)

c(true=tau, estimate=tauhat)
```

Here are cumulative counts and the true end expected
cumulative cell probabilities:

```{r}
plot(stepfun(1:6, c(0, cumsum(counts[,"1"])/sum(counts[,"1"]))), 
  do.points=FALSE, main="Binned CDF",
  ylab="Cumulative probability", 
  xlab="Bin radius end point (100 m)")
curve(1-exp(-(x/tau)^2), col=2, add=TRUE)
curve(1-exp(-(x/tauhat)^2), col=4, add=TRUE)
legend("topleft", bty="n", lty=1, col=c(2, 4, 1), 
  legend=c("True", "Estimated", "Empirical"))
```

## Availability bias

We have ignored availability so far when working with bSims, 
but can't continue like that for real data.
What this means, is that $g(0) < 1$, so detecting
an individual 0 distance from the observer depends on
an event (visual or auditory) that would trigger the detection.
For example, if a perfecly camouflaged birds sits in silence,
detection might be difficult. Movement, or a volcalization
can, however, reveal the individual and its location.

add here mor bSims with estimating p and q

```{r}
phi <- 0.5
tau <- 1
Den <- 5

set.seed(1)
l <- bsims_init()
a <- bsims_populate(l, density=Den)
b <- bsims_animate(a, vocal_rate=phi, move_rate=0)
d <- bsims_detect(b, tau=tau, vocal_only=TRUE)

tint <- c(1, 2, 3, 4, 5)
rint <- c(0.5, 1, 1.5, 2) # truncated at 200 m
(tr <- bsims_transcribe(d, tint=tint, rint=rint))
(rem <- tr$removal) # binned new individuals
colSums(rem)
rowSums(rem)
```

```{r fig.width=8,fig.height=8}
plot(d)
if (any(is.infinite(rint))) {
  polygon(0.5*d$extent*c(-1,-1,1,1), 0.5*d$extent*c(-1,1,1,-1),
    border=NA, col="#ff000033")
} else {
  draw_ellipse(0, 0, max(rint), max(rint),
    border=NA, col="#ff000033")
}
draw_ellipse(rep(0, length(rint)), rep(0, length(rint)), 
  rint, rint, border=2)
```

```{r}
fitp <- cmulti.fit(matrix(colSums(rem), 1), matrix(tint, 1), type="rem")
phihat <- exp(fitp$coef)
c(true=phi, estimate=exp(fitp$coef))
(p <- 1-exp(-max(tint)*phihat))

fitq <- cmulti.fit(matrix(rowSums(rem), 1), matrix(rint, 1), type="dis")
tauhat <- exp(fitq$coef)
c(true=tau, estimate=tauhat)
(q <- (tauhat^2/max(rint)^2) * (1-exp(-(max(rint)/tauhat)^2)))

(A <- pi * max(rint)^2)
Dhat <- sum(rem) / (A * p * q)
c(true=Den, estimate=Dhat)
```



Unlimited distance case

```{r}
rint <- c(0.5, 1, 1.5, 2, Inf) # unlimited

(tr <- bsims_transcribe(d, tint=tint, rint=rint))
(rem <- tr$removal) # binned new individuals
colSums(rem)
rowSums(rem)

fitp <- cmulti.fit(matrix(colSums(rem), 1), matrix(tint, 1), type="rem")
phihat <- exp(fitp$coef)
c(true=phi, estimate=phihat)
(p <- 1-exp(-max(tint)*phihat))

fitq <- cmulti.fit(matrix(rowSums(rem), 1), matrix(rint, 1), type="dis")
tauhat <- exp(fitq$coef)
c(true=tau, estimate=tauhat)
q <- 1
(Ahat <- pi * tauhat^2)

Dhat <- sum(rem) / (Ahat * p * q)
c(true=Den, estimate=Dhat)
```

Need to check that replication does give justice to the approach

```{r}
phi <- 0.4
tau <- 0.8
Den <- 1

tint <- c(1, 2, 3)
rint <- c(0.5, 1, 1.5, 2, Inf) # unlimited

tint <- c(3, 5, 10)
rint <- c(0.5, 1, Inf) # unlimited

sim_fun <- function() {
  l <- bsims_init()
  a <- bsims_populate(l, density=Den)
  b <- bsims_animate(a, vocal_rate=phi, move_rate=0)
  d <- bsims_detect(b, tau=tau, vocal_only=TRUE)
  tr <- bsims_transcribe(d, tint=tint, rint=rint)
  tr$rem
}

B <- 200
res <- pbapply::pbreplicate(B, sim_fun(), simplify=FALSE)

## need one excluding unlimited bin
Ddur <- matrix(tint, B, length(tint), byrow=TRUE)
Ydur <- t(sapply(res, function(z) colSums(z)))
summary(Ddur)
summary(Ydur)
colSums(Ydur) / sum(Ydur)
fitp <- cmulti(Ydur | Ddur ~ 1, type="rem")
phihat <- unname(exp(coef(fitp)))
c(true=phi, estimate=phihat)


Ddis1 <- matrix(rint, B, length(rint), byrow=TRUE)
Ydis1 <- t(sapply(res, function(z) rowSums(z)))
colSums(Ydis1) / sum(Ydis1)
fitq1 <- cmulti(Ydis1 | Ddis1 ~ 1, type="dis")
tauhat1 <- unname(exp(fitq1$coef))

Ddis2 <- matrix(rint[-length(rint)], B, length(rint)-1, byrow=TRUE)
Ydis2 <- t(sapply(res, function(z) rowSums(z)[-length(rint)]))
colSums(Ydis2) / sum(Ydis2)
fitq2 <- cmulti(Ydis2 | Ddis2 ~ 1, type="dis")
tauhat2 <- unname(exp(fitq2$coef))

round(c(true=tau, unlimited=tauhat1, truncated=tauhat2), 4)



(p <- 1-exp(-max(tint)*phihat))
q1 <- 1
(q2 <- (tauhat2^2/max(rint[-length(rint)])^2) * (1-exp(-(max(rint[-length(rint)])/tauhat2)^2)))
(A1 <- pi * tauhat1^2)
(A2 <- pi * max(rint[-length(rint)])^2)

c(true=Den, 
  unlimited=mean(rowSums(Ydis1)) / (A1 * p * q1),
  truncated=mean(rowSums(Ydis2)) / (A2 * p * q2))


```


## JOSM data

Process TEWA data

### Constant EDR

Fit constant EDR model for TEWA using cmulti

### Variable EDR

variable tau: habitat effect (continuous case?)

discrete: land cover, observer effects

do model selection and pick the best model

## Estimating abundance

bSims and TEWA as in previous chapter, but with q this time

contrast fixed effects with offsets -- motivation for ARU


Sometimes, a recording is made at the survey location
that is listened to and transcribed in the lab
using headphones and possibly a computer screen.
This presents new challenges, and also new opportunities
for analysis of count data -- and is the topic of the next chapter.

FIXME Add exercises !!! 

