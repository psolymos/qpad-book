# Introduction {#intro}

> All assumptions are violated, but some are more than others

A comparison of apples and oranges occurs when two items or 
groups of items are compared that cannot be practically compared 
([Wikipedia](https://en.wikipedia.org/wiki/Apples_and_oranges)).
The way we measure things can have a big impact on the outcome
of that measurement. For example, you might say that
"I saw 5 robins walking down the road", while I might say that
"I only saw one robin while sitting on my porch".
Who say more robins? If looking at only the numeric results,
you saw more robins than me. But this seems like
an apples to oranges comparison.

To compare apples to apples, we need to agree on a comparable
measurement scheme, or at least figure out how does _effort_
affect the observations.

Effort in our example can depend on, e.g.
the _area_ of the physical space searched,
the amount of _time_ spent, etc.
The outcome might further affected by
weather, time of year, time of day, location,
experience and skill level of the observer.

All these factors can affect the observed count.
Which brings us to the definition of a _point count_:
a trained observer 
records all the birds 
seen and heard 
from a point count station 
for a set period of time
within a defined distance radius.

Point count duration and distance have profound effect
on the counts, as shown in Figure \@ref(fig:intro-1)
showing that a 10-min unlimited distance count 
is roughly 300% increased compared to 3-min 50-m counts 
(averaged across 54 species of boreal songbirds, [@matsuoka2014]).

```{r intro-1,echo=FALSE,fig.cap='Effects of duration and distance on mean counts, from [@matsuoka2014].',out.width='80%'}
include_graphics("images/matsuoka-2014-fig-2.png")
```

Point counts are commonly used to answer questions like:

- How many? (Abundance, density, population size)
- Is this location part of the range? (0/1)
- How is abundance changing in space? (Distribution)
- How is abundance changing in time? (Trend)
- What is the effect of a treatment on abundance?

## Design-based approaches

Standards and recommendations can
maximize efficiency in the numbers of birds and species counted,
minimize extraneous variability in the counts.

But programs started to deviate from standards:
_"For example, only 3% of 196,000 point counts conducted during the period
1992--2011 across Alaska and Canada followed the standards recommended for the count period and count radius"_ ([@matsuoka2014]).
Figure \@ref(fig:intro-2) show how point count protocol varies
across the boreal region of North America.

```{r intro-2,echo=FALSE,fig.cap='Survey methodology variation (colors) among contributed projects in the Boreal Avian Modelling (BAM) data base, from [@barker2015].',out.width='80%'}
include_graphics("images/barker-2015-fig-2.png")
```


```{block2, type='rmdexercise'}
**Exercise**

In what regard can protocols differ?

What might drive protocol variation among projects?

Why have we abandoned following protocols?
```


## Model-based approaches

Detection probabilities might vary even with fixed effort 
(we'll cover this more later),
and programs might have their own goals and constraints (access, training, etc).
These constraints would make it almost impossible, and potentially costly
to set up very specific standards.

Labour intensive methods for unmarked populations 
have come to the forefront, and computing power of 
personal computers opened the door for model-based approaches,
that can accomodate more variation given enough information
in the observed data. These methods often rely on ancillary
information and often some sort of replication. 

Some of the commonly used model-based approaches are:

- double observer ([Nichols et al. 2000](https://doi.org/10.1642/0004-8038(2000)117[0393:ADOAFE]2.0.CO;2)),
- distance sampling ([Buckland et al. 2001](https://global.oup.com/academic/product/introduction-to-distance-sampling-9780198509271)),
- removal sampling ([Farnsworth et al. 2002](https://doi.org/10.1642/0004-8038(2002)119[0414:ARMFED]2.0.CO;2)),
- multiple visit occupancy ([MacKenzie et al. 2002](https://doi.org/10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2)),
- multiple visit abundance ([Royle 2004](https://doi.org/10.1111/j.0006-341X.2004.00142.x)).

Models come with assumptions, such as:

- population is closed during multiple visits,
- observers are independent,
- all individuals emit cues with identical rates,
- spatial distribution of individuals is uniform,
- etc.

Although assumptions are everywhere, we are really good at ignoring 
and violating them.

```{block2, type='rmdexercise'}
**Exercise**

Can you mention some assumptions from everyday life?

Can you explain why we neglect/violate assumptions in these situations?
```

Assumptions are violated, because we seek simplicity.
The main question we have to ask: _does it matter in practice_ if 
we violate the assumptions?

## Our approach

In this book and course, we will critically evaluate common assumptions made
when analyzing point count data using the following approach:

1. we will introduce a concept,
2. understand how we can infer it from data,
3. then we recreate the situation _in silico_,
4. and see how the outcome changes as we make different assumptions.

It is guaranteed that we will violate every assumption we make.
To get away with it, we need to understand how much is too much,
and whether it has an impact in practice.
If there is a practical consequence, we will look at ways to minimize
that effects -- so that we can safely ignore the assumption.

